{"cells":[{"cell_type":"code","source":["!pip -qq install torchmetrics "],"metadata":{"id":"aRCw_9zr6zTo","executionInfo":{"status":"ok","timestamp":1656782906014,"user_tz":-540,"elapsed":2936,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"WJVeGDc8d-Ms","executionInfo":{"status":"ok","timestamp":1656782906015,"user_tz":-540,"elapsed":4,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["import torch\n","import torchvision\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","import torchvision.models as models\n","from torch.autograd import Variable\n","from torch import optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import cv2\n","from PIL import Image\n","from tqdm import tqdm_notebook as tqdm\n","import random\n","from matplotlib import pyplot as plt\n","import time\n","from torchvision.datasets import ImageFolder\n","from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","from tqdm import tqdm\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","import zipfile"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xSvZd6UwJ4F7","executionInfo":{"status":"ok","timestamp":1656782919134,"user_tz":-540,"elapsed":13123,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["path_to_zip_file = '/content/drive/MyDrive/DL_study_179/data/animal-10/archive.zip'\n","directory_to_extract_to = '.'\n","\n","if not os.path.isdir('/content/raw-img'):\n","    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","        zip_ref.extractall(directory_to_extract_to)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"JledV1_Yef-S","executionInfo":{"status":"ok","timestamp":1656782919135,"user_tz":-540,"elapsed":6,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["translate = {\n","    \"cane\": \"dog\", \n","    \"cavallo\": \"horse\", \n","    \"elefante\": \"elephant\", \n","    \"farfalla\": \"butterfly\", \n","    \"gallina\": \"chicken\", \n","    \"gatto\": \"cat\", \n","    \"mucca\": \"cow\", \n","    \"pecora\": \"sheep\", \n","    \"ragno\": \"spider\",\n","    \"scoiattolo\": \"squirrel\", \n","    \"dog\": \"cane\", \n","    \"horse\": \"cavallo\", \n","    \"elephant\" : \"elefante\", \n","    \"butterfly\": \"farfalla\", \n","    \"chicken\": \"gallina\", \n","    \"cat\": \"gatto\", \n","    \"cow\": \"mucca\", \n","    \"sheep\": \"pecora\",\n","    \"spider\": \"ragno\", \n","    \"squirrel\": \"scoiattolo\"\n","    }"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"j-qUUTJKtw6h","executionInfo":{"status":"ok","timestamp":1656782919136,"user_tz":-540,"elapsed":6,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["CLASS_NUMBER = {\n","    \"butterfly\": 0,\n","    \"cat\": 1,\n","    \"chicken\": 2,\n","    \"cow\": 3,\n","    \"dog\": 4,\n","    \"elephant\": 5,\n","    \"horse\": 6,\n","    \"sheep\": 7,\n","    \"spider\": 8,\n","    \"squirrel\": 9\n","}"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TG0BAnB7egXi","executionInfo":{"status":"ok","timestamp":1656783001207,"user_tz":-540,"elapsed":82077,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["import os\n","import random\n","import cv2\n","import numpy as np\n","\n","\n","def image_resize(img):\n","    # 세로 > 가로\n","    if(img.shape[0] > img.shape[1]):\n","        tile_size = (int(img.shape[1]*256/img.shape[0]), 256)\n","    else:\n","        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n","\n","    #centering\n","    img = cv2.resize(img, dsize=tile_size)\n","    \n","    size = [256,256]\n","    \n","    img_size = img.shape[:2]\n","    \n","    # centering\n","    row = (size[1] - img_size[0]) // 2\n","    col = (size[0] - img_size[1]) // 2\n","    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n","    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n","\n","    return resized\n","\n","def save_img(save_path, folder_name, image_list):\n","    new_name = translate[folder_name]\n","    folder_path = os.path.join(save_path, new_name)\n","    \n","    if not os.path.isdir(folder_path):\n","        os.mkdir(folder_path)\n","    \n","    for i, image in enumerate(image_list):\n","        img = cv2.imread(image)\n","        img = image_resize(img)\n","        image_path = os.path.join(folder_path, new_name + \"_\" + str(i) + \".jpg\")\n","        cv2.imwrite(image_path, img)\n","\n","\n","if __name__ == \"__main__\":\n","    random.seed(100)\n","    \n","    BASE_PATH = \".\"\n","    BASE_PATH = os.path.abspath(BASE_PATH)  \n","    source_path = os.path.join(BASE_PATH, \"raw-img\")\n","    assert os.path.isdir(source_path)\n","    \n","    train_path = os.path.join(BASE_PATH, \"train_img\")\n","    test_path = os.path.join(BASE_PATH, \"test_img\")\n","    \n","    if not os.path.isdir(train_path):\n","        os.mkdir(train_path)\n","    if not os.path.isdir(test_path):\n","        os.mkdir(test_path)\n","\n","    folder_list = os.listdir(source_path)\n","\n","    if '.DS_Store' in folder_list:\n","        folder_list.remove('.DS_Store')\n","\n","\n","    img_set = {}\n","    for folder in folder_list:\n","        folder_path = os.path.join(source_path, folder)\n","        image_list = os.listdir(folder_path)\n","        \n","        image_path_list = []\n","        for image in image_list:\n","            image_path_list.append(os.path.join(folder_path, image))\n","        img_set[folder] = image_path_list\n","\n","\n","    for folder in img_set:\n","        random.shuffle(img_set[folder])\n","        train_length = int(len(img_set[folder]) * 0.8)\n","        \n","        train_list = img_set[folder][:train_length]\n","        test_list = img_set[folder][train_length:]\n","\n","        save_img(train_path, folder, train_list)\n","        save_img(test_path, folder, test_list)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"o9XKSWYCd_Ig","executionInfo":{"status":"ok","timestamp":1656783001208,"user_tz":-540,"elapsed":12,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["class ImageTransform():    \n","    def __init__(self, resize, mean, std):\n","        self.data_transform = {\n","            'train': transforms.Compose([\n","                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std)\n","            ]),\n","            'val': transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.CenterCrop(resize),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std)\n","            ])\n","        }\n","        \n","    def __call__(self, img, phase):\n","        return self.data_transform[phase](img)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"XYy4XgT38yoP","executionInfo":{"status":"ok","timestamp":1656783402466,"user_tz":-540,"elapsed":1053,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["size = 256\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","batch_size = 32\n","num_epochs = 5"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"yiXZpk_r98VH","executionInfo":{"status":"ok","timestamp":1656786929781,"user_tz":-540,"elapsed":433,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["train_transforms = transforms.Compose([\n","                           transforms.Resize((256, 256)),\n","                           transforms.RandomRotation(5),\n","                           transforms.RandomHorizontalFlip(0.5),\n","                           transforms.ToTensor(),\n","                        #    transforms.Normalize(mean=mean,std=std)\n","                           ])\n","\n","test_transforms = transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.CenterCrop(256),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std)\n","            ])"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"GKPu4LC6Ofw3","executionInfo":{"status":"ok","timestamp":1656786933766,"user_tz":-540,"elapsed":1,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["train_path = '/content/train_img'\n","test_path = '/content/test_img'\n","\n","train_dataset = torchvision.datasets.ImageFolder(\n","    train_path,\n","    transform=train_transforms\n",")\n","\n","test_dataset = torchvision.datasets.ImageFolder(\n","    test_path,\n","    transform=test_transforms\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"30QUWaugXLmy","executionInfo":{"status":"ok","timestamp":1656783403036,"user_tz":-540,"elapsed":5,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["def save_model(model, path, kfold, epoch):\n","    # PATH = '/content/drive/MyDrive/DL_study_179/weight/week2/'\n","    torch.save(model, '{}{}_{}_model.pt'.format(path, kfold, epoch))  # 전체 모델 저장\n","    # torch.save(model.state_dict(), '{}{}_{}_model_state_dict.pt'.format(path, kfold, epoch))  # 모델 객체의 state_dict 저장\n","    # torch.save({\n","    #     'model': model.state_dict(),\n","    #     'optimizer': optimizer.state_dict()\n","    # }, '{}{}_{}_all.tar'.format(path, kfold, epoch))  # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"BgkBw0yxMkt7","executionInfo":{"status":"ok","timestamp":1656783403036,"user_tz":-540,"elapsed":5,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["def train_model(model, dataloaders_dict, criterion, optimizer, kfold, num_epochs, save_path):\n","    model.to(device)\n","\n","    history = {'train_loss': [], 'val_loss': [],'train_acc': [],'val_acc': []}\n","\n","    torch.backends.cudnn.benchmark = True\n","\n","    for epoch in range(num_epochs):\n","        # print('-' * 20)\n","        print('Epoch {:02d}/{} | '.format(epoch+1, num_epochs), end='')\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","            \n","            epoch_loss = 0.0\n","            epoch_corrects = 0\n","\n","            # if (epoch == 0) and (phase == 'train'):\n","            #     continue\n","\n","            for inputs, labels in dataloaders_dict[phase]:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                    \n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","                    \n","\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n","            \n","            history[phase+'_loss'].append(epoch_loss)\n","            history[phase+'_acc'].append(epoch_acc.cpu())\n","            print('{} | Loss: {:.4f} Acc: {:.4f} | '.format(phase, epoch_loss, epoch_acc), end='')\n","        print()\n","\n","        # save_model(model, save_path, kfold, epoch)\n","    return history"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50KK22wQ-KyR","outputId":"7c58924c-7e4b-42b6-d12f-4cd546a0321e","executionInfo":{"status":"ok","timestamp":1656786146944,"user_tz":-540,"elapsed":2743913,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------\n","K-fold: 1\n","--------------------\n","Epoch 01/5 | train | Loss: 0.3931 Acc: 0.8904 | val | Loss: 0.1509 Acc: 0.9568 | \n","Epoch 02/5 | train | Loss: 0.1462 Acc: 0.9579 | val | Loss: 0.1320 Acc: 0.9601 | \n","Epoch 03/5 | train | Loss: 0.1073 Acc: 0.9685 | val | Loss: 0.1256 Acc: 0.9632 | \n","Epoch 04/5 | train | Loss: 0.0778 Acc: 0.9778 | val | Loss: 0.1267 Acc: 0.9628 | \n","Epoch 05/5 | train | Loss: 0.0583 Acc: 0.9856 | val | Loss: 0.1194 Acc: 0.9661 | \n","--------------------\n","K-fold: 2\n","--------------------\n","Epoch 01/5 | train | Loss: 0.3946 Acc: 0.8916 | val | Loss: 0.1548 Acc: 0.9553 | \n","Epoch 02/5 | train | Loss: 0.1443 Acc: 0.9592 | val | Loss: 0.1342 Acc: 0.9592 | \n","Epoch 03/5 | train | Loss: 0.1072 Acc: 0.9704 | val | Loss: 0.1190 Acc: 0.9599 | \n","Epoch 04/5 | train | Loss: 0.0810 Acc: 0.9778 | val | Loss: 0.1083 Acc: 0.9673 | \n","Epoch 05/5 | train | Loss: 0.0610 Acc: 0.9834 | val | Loss: 0.1102 Acc: 0.9673 | \n","--------------------\n","K-fold: 3\n","--------------------\n","Epoch 01/5 | train | Loss: 0.3919 Acc: 0.8952 | val | Loss: 0.1488 Acc: 0.9561 | \n","Epoch 02/5 | train | Loss: 0.1474 Acc: 0.9579 | val | Loss: 0.1181 Acc: 0.9635 | \n","Epoch 03/5 | train | Loss: 0.1088 Acc: 0.9686 | val | Loss: 0.1156 Acc: 0.9659 | \n","Epoch 04/5 | train | Loss: 0.0835 Acc: 0.9759 | val | Loss: 0.1083 Acc: 0.9687 | \n","Epoch 05/5 | train | Loss: 0.0600 Acc: 0.9832 | val | Loss: 0.1027 Acc: 0.9718 | \n","--------------------\n","K-fold: 4\n","--------------------\n","Epoch 01/5 | train | Loss: 0.3882 Acc: 0.8951 | val | Loss: 0.1380 Acc: 0.9577 | \n","Epoch 02/5 | train | Loss: 0.1457 Acc: 0.9581 | val | Loss: 0.1184 Acc: 0.9673 | \n","Epoch 03/5 | train | Loss: 0.1036 Acc: 0.9706 | val | Loss: 0.1204 Acc: 0.9630 | \n","Epoch 04/5 | train | Loss: 0.0818 Acc: 0.9781 | val | Loss: 0.1107 Acc: 0.9680 | \n","Epoch 05/5 | train | Loss: 0.0629 Acc: 0.9820 | val | Loss: 0.1119 Acc: 0.9632 | \n","--------------------\n","K-fold: 5\n","--------------------\n","Epoch 01/5 | train | Loss: 0.3848 Acc: 0.8979 | val | Loss: 0.1544 Acc: 0.9558 | \n","Epoch 02/5 | train | Loss: 0.1428 Acc: 0.9581 | val | Loss: 0.1365 Acc: 0.9604 | \n","Epoch 03/5 | train | Loss: 0.1059 Acc: 0.9693 | val | Loss: 0.1188 Acc: 0.9656 | \n","Epoch 04/5 | train | Loss: 0.0763 Acc: 0.9777 | val | Loss: 0.1139 Acc: 0.9692 | \n","Epoch 05/5 | train | Loss: 0.0615 Acc: 0.9832 | val | Loss: 0.1131 Acc: 0.9694 | \n"]}],"source":["kf = StratifiedKFold(n_splits=5)\n","foldperf={}\n","save_path = '/content/drive/MyDrive/DL_study_179/weight/week2/'\n","for i, (train_index, val_index) in enumerate(kf.split(train_dataset, train_dataset.targets)):\n","\n","    pretrained_model=models.resnet18(pretrained=True)\n","    pretrained_model.fc = nn.Linear(512, 10)\n","\n","    # optimizer = optim.Adam(pretrained_model.parameters(), lr=0.001)\n","    optimizer = optim.SGD(pretrained_model.parameters(), lr=0.001, momentum=0.9)\n","    criterion = nn.CrossEntropyLoss().to(device)\n","\n","    # print(\"train_index : {}, val_index : {}\".format(len(train_index), len(val_index)))\n","    train = torch.utils.data.Subset(train_dataset, train_index)\n","    valid = torch.utils.data.Subset(train_dataset, val_index)\n","\n","\n","    trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","    validloader = torch.utils.data.DataLoader(valid, batch_size=batch_size)\n","    \n","    \n","    dataloaders_dict = {\"train\" : trainloader, \"val\": validloader}\n","    \n","    print('-' * 20)\n","    print('K-fold: {}'.format(i+1))\n","    print('-' * 20)\n","    history = train_model(pretrained_model, dataloaders_dict, criterion, optimizer, i+1, num_epochs, save_path)\n","\n","    foldperf['fold{}'.format(i+1)] = history\n"]},{"cell_type":"code","source":["# pretrained_model=models.resnet18(pretrained=False)\n","# pretrained_model.fc = nn.Linear(512, 10)\n","# # optimizer = optim.Adam(pretrained_model.parameters(), lr=0.001)\n","# optimizer = optim.SGD(pretrained_model.parameters(), lr=0.001, momentum=0.9)\n","# criterion = nn.CrossEntropyLoss().to(device)\n","# # print(\"train_index : {}, val_index : {}\".format(len(train_index), len(val_index)))\n","\n","\n","# pt_path = '/content/drive/MyDrive/DL_study_179/weight/week2/3_49_model.pt'\n","# loaded_model = torch.load(pt_path)\n","\n","# loaded_model.to(device)"],"metadata":{"id":"Pr-vVAoZIIYb","executionInfo":{"status":"ok","timestamp":1656786153867,"user_tz":-540,"elapsed":6932,"user":{"displayName":"HS","userId":"14086807755961934596"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb9866af-1fa8-4395-a848-ef1107999164"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["category_list = os.listdir('/content/train_img')\n","\n","test_cate_dirs_dict = {}\n","for category in category_list:\n","    test_cate_dirs_dict[category] = '/content/test_img/' + category\n","\n","\n","test_cate_images_filepaths = {}\n","for cate, cate_dir in test_cate_dirs_dict.items():\n","    test_cate_images_filepaths[cate] = sorted([os.path.join(cate_dir, f) for f in os.listdir(cate_dir)])\n","\n","test_images_filepaths = []\n","\n","for path, image_list in test_cate_images_filepaths.items():\n","    test_images_filepaths += image_list\n","\n","test_correct_images_filepaths = [i for i in test_images_filepaths if cv2.imread(i) is not None]\n","\n","\n","random.seed(42)\n","random.shuffle(test_correct_images_filepaths)\n","\n","test_images_filepaths = test_correct_images_filepaths[:]\n"],"metadata":{"id":"H7J-knsW1j40","executionInfo":{"status":"ok","timestamp":1656787132590,"user_tz":-540,"elapsed":5737,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["class Animal10Dataset(Dataset):\n","    def __init__(self, file_list, transform=None, phase='train'):\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.phase = phase\n","    \n","    def __len__(self):\n","        return len(self.file_list)\n","    \n","    def __getitem__(self, idx):\n","        img_path = self.file_list[idx]\n","        img = Image.open(img_path)\n","        img_transformed = self.transform(img, self.phase)\n","\n","        label = img_path.split('/')[-1].split('_')[0]\n","        label = CLASS_NUMBER[label]\n","        return img_transformed, label"],"metadata":{"id":"AGdSuV0JNT6s","executionInfo":{"status":"ok","timestamp":1656787147333,"user_tz":-540,"elapsed":2,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["test_dataset = Animal10Dataset(test_images_filepaths, transform=ImageTransform(size, mean, std), phase='val')\n","test_iterator = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"],"metadata":{"id":"g9qJ-mGGNaMD","executionInfo":{"status":"ok","timestamp":1656787276798,"user_tz":-540,"elapsed":2,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["all_preds = torch.Tensor([]).to(device)\n","all_labels = torch.Tensor([]).to(device)\n","for images, labels in test_iterator:\n","    \n","    images, labels = images.to(device), labels.to(device)\n","    preds=pretrained_model(images).argmax(dim=1).to(device)\n","    all_preds = torch.cat((all_preds, preds), dim=0)\n","    all_labels = torch.cat((all_labels, labels), dim=0)"],"metadata":{"id":"Sg-yoXBy6szg","executionInfo":{"status":"ok","timestamp":1656787291517,"user_tz":-540,"elapsed":13327,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["from torchmetrics import ConfusionMatrix\n","all_preds = all_preds.clone().detach().type(torch.IntTensor).to(device)\n","all_labels = all_labels.clone().detach().type(torch.IntTensor).to(device)"],"metadata":{"id":"Mqr0ELN2_Jrh","executionInfo":{"status":"ok","timestamp":1656787291517,"user_tz":-540,"elapsed":25,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["confmat = ConfusionMatrix(num_classes=10).to(device)\n","confusion_matrix = confmat(all_preds, all_labels).cpu()"],"metadata":{"id":"tIXikVNDVhp7","executionInfo":{"status":"ok","timestamp":1656787291517,"user_tz":-540,"elapsed":22,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["confusion_matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baAYg9SOUsr4","executionInfo":{"status":"ok","timestamp":1656787291518,"user_tz":-540,"elapsed":22,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"877e8e8e-83f0-4392-d53f-0645545d4f95"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 53,   6,   0,   0, 311,   0,   0,   0,  53,   0],\n","        [ 48,  17,   0,   0, 228,   0,   0,   0,  41,   0],\n","        [ 84,  17,   0,   0, 396,   0,   0,   0, 123,   0],\n","        [ 31,  11,   0,   0, 292,   0,   0,   0,  40,   0],\n","        [124,  53,   0,   0, 653,   0,   0,   0, 143,   0],\n","        [ 36,  13,   0,   0, 210,   0,   0,   0,  31,   0],\n","        [ 68,  23,   0,   0, 387,   0,   0,   0,  47,   0],\n","        [ 42,  20,   0,   0, 238,   0,   0,   0,  64,   0],\n","        [262,  31,   0,   0, 472,   0,   0,   0, 200,   0],\n","        [ 44,  13,   0,   0, 235,   0,   0,   0,  81,   0]])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["from torchmetrics import F1Score\n","f1 = F1Score(num_classes=10).to(device)\n","f1_score = f1(all_preds, all_labels).cpu()"],"metadata":{"id":"Z9mxXn7iVeF-","executionInfo":{"status":"ok","timestamp":1656786999387,"user_tz":-540,"elapsed":422,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["f1_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QAnebqDWdM5","executionInfo":{"status":"ok","timestamp":1656786999809,"user_tz":-540,"elapsed":1,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"674acb70-0803-438e-e565-fa17026fb350"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.1761)"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["```\n","tensor(0.9599)\n","```"],"metadata":{"id":"OQ_Yp0iKWe_o"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"DL_study_179_week2-1.ipynb의 사본","provenance":[],"mount_file_id":"12IUAqE_bq3kRrhyut9wQ5r4IbR9GsgLY","authorship_tag":"ABX9TyNEH84zGiB1ZjGZkURZh8AF"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}