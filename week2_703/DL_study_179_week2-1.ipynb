{"cells":[{"cell_type":"code","source":["!pip -qq install torchmetrics "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRCw_9zr6zTo","executionInfo":{"status":"ok","timestamp":1656756666416,"user_tz":-540,"elapsed":5277,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"8ab90542-7e1d-41f4-e332-b18abc294d41"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |▉                               | 10 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 92 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 245 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 256 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 266 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 276 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 286 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 296 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 307 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 317 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 327 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 337 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 348 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 358 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 368 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 378 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 389 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 399 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 409 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 419 kB 4.9 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"WJVeGDc8d-Ms","executionInfo":{"status":"ok","timestamp":1656756671060,"user_tz":-540,"elapsed":4647,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["import torch\n","import torchvision\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","import torchvision.models as models\n","from torch.autograd import Variable\n","from torch import optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import cv2\n","from PIL import Image\n","from tqdm import tqdm_notebook as tqdm\n","import random\n","from matplotlib import pyplot as plt\n","import time\n","from torchvision.datasets import ImageFolder\n","from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","from tqdm import tqdm\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","import zipfile"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xSvZd6UwJ4F7","executionInfo":{"status":"ok","timestamp":1656756686469,"user_tz":-540,"elapsed":15413,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["path_to_zip_file = '/content/drive/MyDrive/DL_study_179/data/animal-10/archive.zip'\n","directory_to_extract_to = '.'\n","\n","if not os.path.isdir('/content/raw-img'):\n","    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","        zip_ref.extractall(directory_to_extract_to)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"JledV1_Yef-S","executionInfo":{"status":"ok","timestamp":1656756686469,"user_tz":-540,"elapsed":13,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["translate = {\n","    \"cane\": \"dog\", \n","    \"cavallo\": \"horse\", \n","    \"elefante\": \"elephant\", \n","    \"farfalla\": \"butterfly\", \n","    \"gallina\": \"chicken\", \n","    \"gatto\": \"cat\", \n","    \"mucca\": \"cow\", \n","    \"pecora\": \"sheep\", \n","    \"ragno\": \"spider\",\n","    \"scoiattolo\": \"squirrel\", \n","    \"dog\": \"cane\", \n","    \"horse\": \"cavallo\", \n","    \"elephant\" : \"elefante\", \n","    \"butterfly\": \"farfalla\", \n","    \"chicken\": \"gallina\", \n","    \"cat\": \"gatto\", \n","    \"cow\": \"mucca\", \n","    \"sheep\": \"pecora\",\n","    \"spider\": \"ragno\", \n","    \"squirrel\": \"scoiattolo\"\n","    }"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"j-qUUTJKtw6h","executionInfo":{"status":"ok","timestamp":1656756686470,"user_tz":-540,"elapsed":11,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["CLASS_NUMBER = {\n","    \"butterfly\": 0,\n","    \"cat\": 1,\n","    \"chicken\": 2,\n","    \"cow\": 3,\n","    \"dog\": 4,\n","    \"elephant\": 5,\n","    \"horse\": 6,\n","    \"sheep\": 7,\n","    \"spider\": 8,\n","    \"squirrel\": 9\n","}"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TG0BAnB7egXi","executionInfo":{"status":"ok","timestamp":1656756775484,"user_tz":-540,"elapsed":89024,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["import os\n","import random\n","import cv2\n","import numpy as np\n","\n","\n","def image_resize(img):\n","    # 세로 > 가로\n","    if(img.shape[0] > img.shape[1]):\n","        tile_size = (int(img.shape[1]*256/img.shape[0]), 256)\n","    else:\n","        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n","\n","    #centering\n","    img = cv2.resize(img, dsize=tile_size)\n","    \n","    size = [256,256]\n","    \n","    img_size = img.shape[:2]\n","    \n","    # centering\n","    row = (size[1] - img_size[0]) // 2\n","    col = (size[0] - img_size[1]) // 2\n","    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n","    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n","\n","    return resized\n","\n","def save_img(save_path, folder_name, image_list):\n","    new_name = translate[folder_name]\n","    folder_path = os.path.join(save_path, new_name)\n","    \n","    if not os.path.isdir(folder_path):\n","        os.mkdir(folder_path)\n","    \n","    for i, image in enumerate(image_list):\n","        img = cv2.imread(image)\n","        img = image_resize(img)\n","        image_path = os.path.join(folder_path, new_name + \"_\" + str(i) + \".jpg\")\n","        cv2.imwrite(image_path, img)\n","\n","\n","if __name__ == \"__main__\":\n","    random.seed(100)\n","    \n","    BASE_PATH = \".\"\n","    BASE_PATH = os.path.abspath(BASE_PATH)  \n","    source_path = os.path.join(BASE_PATH, \"raw-img\")\n","    assert os.path.isdir(source_path)\n","    \n","    train_path = os.path.join(BASE_PATH, \"train_img\")\n","    test_path = os.path.join(BASE_PATH, \"test_img\")\n","    \n","    if not os.path.isdir(train_path):\n","        os.mkdir(train_path)\n","    if not os.path.isdir(test_path):\n","        os.mkdir(test_path)\n","\n","    folder_list = os.listdir(source_path)\n","\n","    if '.DS_Store' in folder_list:\n","        folder_list.remove('.DS_Store')\n","\n","\n","    img_set = {}\n","    for folder in folder_list:\n","        folder_path = os.path.join(source_path, folder)\n","        image_list = os.listdir(folder_path)\n","        \n","        image_path_list = []\n","        for image in image_list:\n","            image_path_list.append(os.path.join(folder_path, image))\n","        img_set[folder] = image_path_list\n","\n","\n","    for folder in img_set:\n","        random.shuffle(img_set[folder])\n","        train_length = int(len(img_set[folder]) * 0.8)\n","        \n","        train_list = img_set[folder][:train_length]\n","        test_list = img_set[folder][train_length:]\n","\n","        save_img(train_path, folder, train_list)\n","        save_img(test_path, folder, test_list)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"o9XKSWYCd_Ig","executionInfo":{"status":"ok","timestamp":1656756775485,"user_tz":-540,"elapsed":30,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["class ImageTransform():    \n","    def __init__(self, resize, mean, std):\n","        self.data_transform = {\n","            'train': transforms.Compose([\n","                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std)\n","            ]),\n","            'val': transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.CenterCrop(resize),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std)\n","            ])\n","        }\n","        \n","    def __call__(self, img, phase):\n","        return self.data_transform[phase](img)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"XYy4XgT38yoP","executionInfo":{"status":"ok","timestamp":1656758365561,"user_tz":-540,"elapsed":336,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["size = 256\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","batch_size = 32\n","num_epochs = 50"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"yiXZpk_r98VH","executionInfo":{"status":"ok","timestamp":1656758365832,"user_tz":-540,"elapsed":8,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["train_transforms = transforms.Compose([\n","                           transforms.Resize((256, 256)),\n","                           transforms.RandomRotation(5),\n","                           transforms.RandomHorizontalFlip(0.5),\n","                           transforms.ToTensor(),\n","                        #    transforms.Normalize(mean=mean,std=std)\n","                           ])\n","\n","test_transforms = transforms.Compose([\n","                           transforms.Resize((256, 256)),\n","                           transforms.ToTensor(),\n","                           transforms.Normalize(mean=mean,std=std)])"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"GKPu4LC6Ofw3","executionInfo":{"status":"ok","timestamp":1656758365833,"user_tz":-540,"elapsed":7,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["train_path = '/content/train_img'\n","test_path = '/content/test_img'\n","\n","train_dataset = torchvision.datasets.ImageFolder(\n","    train_path,\n","    transform=train_transforms\n",")\n","\n","test_dataset = torchvision.datasets.ImageFolder(\n","    test_path,\n","    transform=test_transforms\n",")"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"30QUWaugXLmy","executionInfo":{"status":"ok","timestamp":1656758366109,"user_tz":-540,"elapsed":2,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["def save_model(model, path, kfold, epoch):\n","    # PATH = '/content/drive/MyDrive/DL_study_179/weight/week2/'\n","    torch.save(model, '{}{}_{}_model.pt'.format(path, kfold, epoch))  # 전체 모델 저장\n","    # torch.save(model.state_dict(), '{}{}_{}_model_state_dict.pt'.format(path, kfold, epoch))  # 모델 객체의 state_dict 저장\n","    # torch.save({\n","    #     'model': model.state_dict(),\n","    #     'optimizer': optimizer.state_dict()\n","    # }, '{}{}_{}_all.tar'.format(path, kfold, epoch))  # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"BgkBw0yxMkt7","executionInfo":{"status":"ok","timestamp":1656758367016,"user_tz":-540,"elapsed":4,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[],"source":["def train_model(model, dataloaders_dict, criterion, optimizer, kfold, num_epochs, save_path):\n","    model.to(device)\n","\n","    history = {'train_loss': [], 'val_loss': [],'train_acc': [],'val_acc': []}\n","\n","    torch.backends.cudnn.benchmark = True\n","\n","    for epoch in range(num_epochs):\n","        # print('-' * 20)\n","        print('Epoch {:02d}/{} | '.format(epoch+1, num_epochs), end='')\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","            \n","            epoch_loss = 0.0\n","            epoch_corrects = 0\n","\n","            # if (epoch == 0) and (phase == 'train'):\n","            #     continue\n","\n","            for inputs, labels in dataloaders_dict[phase]:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                    \n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","                    \n","\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n","            \n","            history[phase+'_loss'].append(epoch_loss)\n","            history[phase+'_acc'].append(epoch_acc)\n","            print('{} | Loss: {:.4f} Acc: {:.4f} | '.format(phase, epoch_loss, epoch_acc), end='')\n","        print()\n","\n","        save_model(model, save_path, kfold, epoch)\n","    return history"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50KK22wQ-KyR","outputId":"a4124483-92f1-4c4f-aee8-a727c3c645dc","executionInfo":{"status":"ok","timestamp":1656780781070,"user_tz":-540,"elapsed":22413349,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------\n","K-fold: 1\n","--------------------\n","Epoch 01/50 | train | Loss: 1.9696 Acc: 0.2994 | val | Loss: 2.0198 Acc: 0.3262 | \n","Epoch 02/50 | train | Loss: 1.5965 Acc: 0.4435 | val | Loss: 2.2014 Acc: 0.3231 | \n","Epoch 03/50 | train | Loss: 1.3591 Acc: 0.5278 | val | Loss: 1.3672 Acc: 0.5258 | \n","Epoch 04/50 | train | Loss: 1.2195 Acc: 0.5826 | val | Loss: 1.2984 Acc: 0.5564 | \n","Epoch 05/50 | train | Loss: 1.1130 Acc: 0.6188 | val | Loss: 1.5212 Acc: 0.4938 | \n","Epoch 06/50 | train | Loss: 1.0171 Acc: 0.6530 | val | Loss: 1.1127 Acc: 0.6363 | \n","Epoch 07/50 | train | Loss: 0.9434 Acc: 0.6781 | val | Loss: 1.0376 Acc: 0.6399 | \n","Epoch 08/50 | train | Loss: 0.8878 Acc: 0.6974 | val | Loss: 1.3369 Acc: 0.5616 | \n","Epoch 09/50 | train | Loss: 0.8295 Acc: 0.7199 | val | Loss: 1.0433 Acc: 0.6547 | \n","Epoch 10/50 | train | Loss: 0.7698 Acc: 0.7365 | val | Loss: 1.1898 Acc: 0.6230 | \n","Epoch 11/50 | train | Loss: 0.7198 Acc: 0.7540 | val | Loss: 0.9957 Acc: 0.6729 | \n","Epoch 12/50 | train | Loss: 0.6714 Acc: 0.7734 | val | Loss: 1.0241 Acc: 0.6817 | \n","Epoch 13/50 | train | Loss: 0.6285 Acc: 0.7884 | val | Loss: 0.9679 Acc: 0.6891 | \n","Epoch 14/50 | train | Loss: 0.5866 Acc: 0.8002 | val | Loss: 0.9227 Acc: 0.6905 | \n","Epoch 15/50 | train | Loss: 0.5450 Acc: 0.8167 | val | Loss: 1.1940 Acc: 0.6538 | \n","Epoch 16/50 | train | Loss: 0.4925 Acc: 0.8339 | val | Loss: 1.0923 Acc: 0.6757 | \n","Epoch 17/50 | train | Loss: 0.4559 Acc: 0.8465 | val | Loss: 1.0256 Acc: 0.6934 | \n","Epoch 18/50 | train | Loss: 0.4174 Acc: 0.8610 | val | Loss: 1.0851 Acc: 0.6798 | \n","Epoch 19/50 | train | Loss: 0.4027 Acc: 0.8675 | val | Loss: 0.7931 Acc: 0.7407 | \n","Epoch 20/50 | train | Loss: 0.3683 Acc: 0.8739 | val | Loss: 1.2474 Acc: 0.6602 | \n","Epoch 21/50 | train | Loss: 0.3301 Acc: 0.8903 | val | Loss: 1.0475 Acc: 0.7118 | \n","Epoch 22/50 | train | Loss: 0.3099 Acc: 0.8977 | val | Loss: 0.8508 Acc: 0.7452 | \n","Epoch 23/50 | train | Loss: 0.2814 Acc: 0.9049 | val | Loss: 1.0609 Acc: 0.7125 | \n","Epoch 24/50 | train | Loss: 0.2520 Acc: 0.9160 | val | Loss: 1.1435 Acc: 0.6913 | \n","Epoch 25/50 | train | Loss: 0.2426 Acc: 0.9179 | val | Loss: 0.8234 Acc: 0.7607 | \n","Epoch 26/50 | train | Loss: 0.2172 Acc: 0.9273 | val | Loss: 0.7457 Acc: 0.7841 | \n","Epoch 27/50 | train | Loss: 0.1927 Acc: 0.9370 | val | Loss: 0.8566 Acc: 0.7703 | \n","Epoch 28/50 | train | Loss: 0.1887 Acc: 0.9355 | val | Loss: 1.0758 Acc: 0.7383 | \n","Epoch 29/50 | train | Loss: 0.1729 Acc: 0.9433 | val | Loss: 0.8634 Acc: 0.7638 | \n","Epoch 30/50 | train | Loss: 0.1549 Acc: 0.9493 | val | Loss: 0.9210 Acc: 0.7760 | \n","Epoch 31/50 | train | Loss: 0.1371 Acc: 0.9554 | val | Loss: 1.1435 Acc: 0.7163 | \n","Epoch 32/50 | train | Loss: 0.1199 Acc: 0.9601 | val | Loss: 1.1049 Acc: 0.7409 | \n","Epoch 33/50 | train | Loss: 0.1153 Acc: 0.9632 | val | Loss: 0.8379 Acc: 0.7815 | \n","Epoch 34/50 | train | Loss: 0.1037 Acc: 0.9662 | val | Loss: 0.9962 Acc: 0.7505 | \n","Epoch 35/50 | train | Loss: 0.0980 Acc: 0.9681 | val | Loss: 0.8171 Acc: 0.7865 | \n","Epoch 36/50 | train | Loss: 0.1006 Acc: 0.9675 | val | Loss: 0.7882 Acc: 0.7913 | \n","Epoch 37/50 | train | Loss: 0.0775 Acc: 0.9749 | val | Loss: 0.8784 Acc: 0.7889 | \n","Epoch 38/50 | train | Loss: 0.0729 Acc: 0.9786 | val | Loss: 0.9858 Acc: 0.7739 | \n","Epoch 39/50 | train | Loss: 0.0730 Acc: 0.9773 | val | Loss: 1.1593 Acc: 0.7290 | \n","Epoch 40/50 | train | Loss: 0.0716 Acc: 0.9767 | val | Loss: 0.8556 Acc: 0.7920 | \n","Epoch 41/50 | train | Loss: 0.0659 Acc: 0.9791 | val | Loss: 1.1306 Acc: 0.7588 | \n","Epoch 42/50 | train | Loss: 0.0575 Acc: 0.9819 | val | Loss: 0.8071 Acc: 0.8073 | \n","Epoch 43/50 | train | Loss: 0.0541 Acc: 0.9833 | val | Loss: 0.9103 Acc: 0.7834 | \n","Epoch 44/50 | train | Loss: 0.0553 Acc: 0.9818 | val | Loss: 0.9658 Acc: 0.7808 | \n","Epoch 45/50 | train | Loss: 0.0477 Acc: 0.9857 | val | Loss: 0.8786 Acc: 0.7899 | \n","Epoch 46/50 | train | Loss: 0.0391 Acc: 0.9893 | val | Loss: 0.9121 Acc: 0.7963 | \n","Epoch 47/50 | train | Loss: 0.0411 Acc: 0.9878 | val | Loss: 0.8557 Acc: 0.8092 | \n","Epoch 48/50 | train | Loss: 0.0356 Acc: 0.9904 | val | Loss: 0.9357 Acc: 0.7870 | \n","Epoch 49/50 | train | Loss: 0.0463 Acc: 0.9862 | val | Loss: 0.8195 Acc: 0.8097 | \n","Epoch 50/50 | train | Loss: 0.0387 Acc: 0.9879 | val | Loss: 0.9417 Acc: 0.7892 | \n","--------------------\n","K-fold: 2\n","--------------------\n","Epoch 01/50 | train | Loss: 1.9904 Acc: 0.2916 | val | Loss: 2.7843 Acc: 0.2142 | \n","Epoch 02/50 | train | Loss: 1.6176 Acc: 0.4347 | val | Loss: 2.5492 Acc: 0.2849 | \n","Epoch 03/50 | train | Loss: 1.3675 Acc: 0.5272 | val | Loss: 1.5068 Acc: 0.4792 | \n","Epoch 04/50 | train | Loss: 1.2203 Acc: 0.5800 | val | Loss: 1.4321 Acc: 0.5351 | \n","Epoch 05/50 | train | Loss: 1.1149 Acc: 0.6121 | val | Loss: 2.6932 Acc: 0.3388 | \n","Epoch 06/50 | train | Loss: 1.0183 Acc: 0.6479 | val | Loss: 1.0079 Acc: 0.6535 | \n","Epoch 07/50 | train | Loss: 0.9519 Acc: 0.6733 | val | Loss: 1.0067 Acc: 0.6633 | \n","Epoch 08/50 | train | Loss: 0.8752 Acc: 0.6990 | val | Loss: 1.2381 Acc: 0.5938 | \n","Epoch 09/50 | train | Loss: 0.8146 Acc: 0.7227 | val | Loss: 1.3246 Acc: 0.5623 | \n","Epoch 10/50 | train | Loss: 0.7629 Acc: 0.7379 | val | Loss: 1.0303 Acc: 0.6660 | \n","Epoch 11/50 | train | Loss: 0.7144 Acc: 0.7544 | val | Loss: 1.1910 Acc: 0.6220 | \n","Epoch 12/50 | train | Loss: 0.6620 Acc: 0.7724 | val | Loss: 1.2520 Acc: 0.6256 | \n","Epoch 13/50 | train | Loss: 0.6213 Acc: 0.7873 | val | Loss: 1.0926 Acc: 0.6557 | \n","Epoch 14/50 | train | Loss: 0.5802 Acc: 0.8011 | val | Loss: 1.6274 Acc: 0.5435 | \n","Epoch 15/50 | train | Loss: 0.5390 Acc: 0.8152 | val | Loss: 1.1080 Acc: 0.6571 | \n","Epoch 16/50 | train | Loss: 0.4944 Acc: 0.8346 | val | Loss: 1.2448 Acc: 0.6488 | \n","Epoch 17/50 | train | Loss: 0.4653 Acc: 0.8385 | val | Loss: 0.8888 Acc: 0.7254 | \n","Epoch 18/50 | train | Loss: 0.4283 Acc: 0.8543 | val | Loss: 0.9589 Acc: 0.7056 | \n","Epoch 19/50 | train | Loss: 0.3896 Acc: 0.8676 | val | Loss: 0.8457 Acc: 0.7397 | \n","Epoch 20/50 | train | Loss: 0.3636 Acc: 0.8754 | val | Loss: 0.9420 Acc: 0.7209 | \n","Epoch 21/50 | train | Loss: 0.3351 Acc: 0.8866 | val | Loss: 0.9036 Acc: 0.7330 | \n","Epoch 22/50 | train | Loss: 0.3057 Acc: 0.9008 | val | Loss: 0.8604 Acc: 0.7438 | \n","Epoch 23/50 | train | Loss: 0.2816 Acc: 0.9067 | val | Loss: 1.1500 Acc: 0.6879 | \n","Epoch 24/50 | train | Loss: 0.2521 Acc: 0.9149 | val | Loss: 0.8766 Acc: 0.7553 | \n","Epoch 25/50 | train | Loss: 0.2331 Acc: 0.9211 | val | Loss: 1.4346 Acc: 0.6631 | \n","Epoch 26/50 | train | Loss: 0.2099 Acc: 0.9303 | val | Loss: 1.2976 Acc: 0.7046 | \n","Epoch 27/50 | train | Loss: 0.1867 Acc: 0.9378 | val | Loss: 0.9390 Acc: 0.7505 | \n","Epoch 28/50 | train | Loss: 0.1799 Acc: 0.9416 | val | Loss: 0.8148 Acc: 0.7739 | \n","Epoch 29/50 | train | Loss: 0.1624 Acc: 0.9461 | val | Loss: 1.0412 Acc: 0.7278 | \n","Epoch 30/50 | train | Loss: 0.1414 Acc: 0.9552 | val | Loss: 0.9015 Acc: 0.7607 | \n","Epoch 31/50 | train | Loss: 0.1396 Acc: 0.9535 | val | Loss: 0.9980 Acc: 0.7519 | \n","Epoch 32/50 | train | Loss: 0.1347 Acc: 0.9561 | val | Loss: 0.9351 Acc: 0.7617 | \n","Epoch 33/50 | train | Loss: 0.1146 Acc: 0.9619 | val | Loss: 1.0798 Acc: 0.7328 | \n","Epoch 34/50 | train | Loss: 0.1005 Acc: 0.9681 | val | Loss: 0.9865 Acc: 0.7674 | \n","Epoch 35/50 | train | Loss: 0.0942 Acc: 0.9701 | val | Loss: 0.9378 Acc: 0.7746 | \n","Epoch 36/50 | train | Loss: 0.0902 Acc: 0.9706 | val | Loss: 1.0318 Acc: 0.7581 | \n","Epoch 37/50 | train | Loss: 0.0868 Acc: 0.9729 | val | Loss: 0.8548 Acc: 0.7832 | \n","Epoch 38/50 | train | Loss: 0.0753 Acc: 0.9774 | val | Loss: 0.9880 Acc: 0.7557 | \n","Epoch 39/50 | train | Loss: 0.0750 Acc: 0.9757 | val | Loss: 0.8776 Acc: 0.7758 | \n","Epoch 40/50 | train | Loss: 0.0695 Acc: 0.9784 | val | Loss: 0.8858 Acc: 0.7841 | \n","Epoch 41/50 | train | Loss: 0.0568 Acc: 0.9837 | val | Loss: 0.9091 Acc: 0.7839 | \n","Epoch 42/50 | train | Loss: 0.0523 Acc: 0.9847 | val | Loss: 0.9484 Acc: 0.7794 | \n","Epoch 43/50 | train | Loss: 0.0442 Acc: 0.9873 | val | Loss: 0.8638 Acc: 0.7968 | \n","Epoch 44/50 | train | Loss: 0.0580 Acc: 0.9820 | val | Loss: 0.8819 Acc: 0.7978 | \n","Epoch 45/50 | train | Loss: 0.0507 Acc: 0.9842 | val | Loss: 1.0579 Acc: 0.7562 | \n","Epoch 46/50 | train | Loss: 0.0611 Acc: 0.9799 | val | Loss: 0.8895 Acc: 0.7927 | \n","Epoch 47/50 | train | Loss: 0.0435 Acc: 0.9865 | val | Loss: 0.9304 Acc: 0.7825 | \n","Epoch 48/50 | train | Loss: 0.0494 Acc: 0.9853 | val | Loss: 1.1101 Acc: 0.7641 | \n","Epoch 49/50 | train | Loss: 0.0497 Acc: 0.9838 | val | Loss: 0.9912 Acc: 0.7760 | \n","Epoch 50/50 | train | Loss: 0.0392 Acc: 0.9891 | val | Loss: 1.0209 Acc: 0.7806 | \n","--------------------\n","K-fold: 3\n","--------------------\n","Epoch 01/50 | train | Loss: 1.9650 Acc: 0.2981 | val | Loss: 2.7650 Acc: 0.2330 | \n","Epoch 02/50 | train | Loss: 1.5846 Acc: 0.4443 | val | Loss: 3.1351 Acc: 0.2708 | \n","Epoch 03/50 | train | Loss: 1.3666 Acc: 0.5319 | val | Loss: 1.8822 Acc: 0.4062 | \n","Epoch 04/50 | train | Loss: 1.2001 Acc: 0.5837 | val | Loss: 2.4049 Acc: 0.3520 | \n","Epoch 05/50 | train | Loss: 1.0900 Acc: 0.6294 | val | Loss: 1.8478 Acc: 0.4281 | \n","Epoch 06/50 | train | Loss: 1.0175 Acc: 0.6518 | val | Loss: 1.0399 Acc: 0.6437 | \n","Epoch 07/50 | train | Loss: 0.9316 Acc: 0.6843 | val | Loss: 1.1654 Acc: 0.6280 | \n","Epoch 08/50 | train | Loss: 0.8688 Acc: 0.7008 | val | Loss: 1.5835 Acc: 0.5320 | \n","Epoch 09/50 | train | Loss: 0.8061 Acc: 0.7253 | val | Loss: 0.9532 Acc: 0.6755 | \n","Epoch 10/50 | train | Loss: 0.7554 Acc: 0.7418 | val | Loss: 0.9881 Acc: 0.6624 | \n","Epoch 11/50 | train | Loss: 0.7054 Acc: 0.7602 | val | Loss: 1.0045 Acc: 0.6612 | \n","Epoch 12/50 | train | Loss: 0.6600 Acc: 0.7791 | val | Loss: 0.8800 Acc: 0.7096 | \n","Epoch 13/50 | train | Loss: 0.6167 Acc: 0.7887 | val | Loss: 1.1016 Acc: 0.6399 | \n","Epoch 14/50 | train | Loss: 0.5804 Acc: 0.8042 | val | Loss: 0.9750 Acc: 0.6851 | \n","Epoch 15/50 | train | Loss: 0.5388 Acc: 0.8131 | val | Loss: 1.2438 Acc: 0.6273 | \n","Epoch 16/50 | train | Loss: 0.5018 Acc: 0.8301 | val | Loss: 0.8590 Acc: 0.7285 | \n","Epoch 17/50 | train | Loss: 0.4638 Acc: 0.8431 | val | Loss: 1.2635 Acc: 0.6337 | \n","Epoch 18/50 | train | Loss: 0.4274 Acc: 0.8572 | val | Loss: 1.3679 Acc: 0.6285 | \n","Epoch 19/50 | train | Loss: 0.3936 Acc: 0.8676 | val | Loss: 1.0612 Acc: 0.6862 | \n","Epoch 20/50 | train | Loss: 0.3635 Acc: 0.8784 | val | Loss: 0.9724 Acc: 0.7132 | \n","Epoch 21/50 | train | Loss: 0.3374 Acc: 0.8861 | val | Loss: 1.2513 Acc: 0.6566 | \n","Epoch 22/50 | train | Loss: 0.3083 Acc: 0.8943 | val | Loss: 0.8394 Acc: 0.7507 | \n","Epoch 23/50 | train | Loss: 0.2860 Acc: 0.9052 | val | Loss: 0.8737 Acc: 0.7428 | \n","Epoch 24/50 | train | Loss: 0.2672 Acc: 0.9109 | val | Loss: 0.9712 Acc: 0.7369 | \n","Epoch 25/50 | train | Loss: 0.2404 Acc: 0.9197 | val | Loss: 1.2280 Acc: 0.6879 | \n","Epoch 26/50 | train | Loss: 0.2221 Acc: 0.9261 | val | Loss: 0.8522 Acc: 0.7555 | \n","Epoch 27/50 | train | Loss: 0.2026 Acc: 0.9320 | val | Loss: 0.8835 Acc: 0.7545 | \n","Epoch 28/50 | train | Loss: 0.1738 Acc: 0.9433 | val | Loss: 1.1803 Acc: 0.7013 | \n","Epoch 29/50 | train | Loss: 0.1623 Acc: 0.9458 | val | Loss: 0.9369 Acc: 0.7447 | \n","Epoch 30/50 | train | Loss: 0.1536 Acc: 0.9494 | val | Loss: 1.4173 Acc: 0.6824 | \n","Epoch 31/50 | train | Loss: 0.1326 Acc: 0.9565 | val | Loss: 1.1376 Acc: 0.7333 | \n","Epoch 32/50 | train | Loss: 0.1278 Acc: 0.9596 | val | Loss: 0.8239 Acc: 0.7777 | \n","Epoch 33/50 | train | Loss: 0.1196 Acc: 0.9616 | val | Loss: 0.8436 Acc: 0.7693 | \n","Epoch 34/50 | train | Loss: 0.1125 Acc: 0.9622 | val | Loss: 1.1241 Acc: 0.7354 | \n","Epoch 35/50 | train | Loss: 0.1046 Acc: 0.9667 | val | Loss: 0.9204 Acc: 0.7586 | \n","Epoch 36/50 | train | Loss: 0.0938 Acc: 0.9681 | val | Loss: 0.7758 Acc: 0.7923 | \n","Epoch 37/50 | train | Loss: 0.0834 Acc: 0.9736 | val | Loss: 1.0061 Acc: 0.7681 | \n","Epoch 38/50 | train | Loss: 0.0874 Acc: 0.9722 | val | Loss: 0.8043 Acc: 0.7982 | \n","Epoch 39/50 | train | Loss: 0.0768 Acc: 0.9757 | val | Loss: 0.9616 Acc: 0.7658 | \n","Epoch 40/50 | train | Loss: 0.0617 Acc: 0.9821 | val | Loss: 0.9887 Acc: 0.7708 | \n","Epoch 41/50 | train | Loss: 0.0634 Acc: 0.9808 | val | Loss: 0.9086 Acc: 0.7755 | \n","Epoch 42/50 | train | Loss: 0.0605 Acc: 0.9809 | val | Loss: 0.9797 Acc: 0.7777 | \n","Epoch 43/50 | train | Loss: 0.0525 Acc: 0.9846 | val | Loss: 0.9591 Acc: 0.7870 | \n","Epoch 44/50 | train | Loss: 0.0509 Acc: 0.9845 | val | Loss: 1.0073 Acc: 0.7837 | \n","Epoch 45/50 | train | Loss: 0.0479 Acc: 0.9857 | val | Loss: 0.9605 Acc: 0.7717 | \n","Epoch 46/50 | train | Loss: 0.0465 Acc: 0.9854 | val | Loss: 0.8142 Acc: 0.8016 | \n","Epoch 47/50 | train | Loss: 0.0491 Acc: 0.9843 | val | Loss: 0.8305 Acc: 0.8016 | \n","Epoch 48/50 | train | Loss: 0.0430 Acc: 0.9863 | val | Loss: 0.9062 Acc: 0.7920 | \n","Epoch 49/50 | train | Loss: 0.0372 Acc: 0.9897 | val | Loss: 0.9140 Acc: 0.7994 | \n","Epoch 50/50 | train | Loss: 0.0343 Acc: 0.9901 | val | Loss: 1.0122 Acc: 0.7956 | \n","--------------------\n","K-fold: 4\n","--------------------\n","Epoch 01/50 | train | Loss: 1.9668 Acc: 0.3021 | val | Loss: 1.8802 Acc: 0.3439 | \n","Epoch 02/50 | train | Loss: 1.5941 Acc: 0.4436 | val | Loss: 1.5943 Acc: 0.4483 | \n","Epoch 03/50 | train | Loss: 1.3625 Acc: 0.5324 | val | Loss: 1.3574 Acc: 0.5364 | \n","Epoch 04/50 | train | Loss: 1.2079 Acc: 0.5806 | val | Loss: 1.3587 Acc: 0.5426 | \n","Epoch 05/50 | train | Loss: 1.0929 Acc: 0.6219 | val | Loss: 1.4606 Acc: 0.5185 | \n","Epoch 06/50 | train | Loss: 1.0039 Acc: 0.6552 | val | Loss: 1.0925 Acc: 0.6195 | \n","Epoch 07/50 | train | Loss: 0.9344 Acc: 0.6777 | val | Loss: 1.3487 Acc: 0.5620 | \n","Epoch 08/50 | train | Loss: 0.8682 Acc: 0.7056 | val | Loss: 1.0600 Acc: 0.6527 | \n","Epoch 09/50 | train | Loss: 0.8092 Acc: 0.7269 | val | Loss: 1.0684 Acc: 0.6468 | \n","Epoch 10/50 | train | Loss: 0.7541 Acc: 0.7438 | val | Loss: 1.1723 Acc: 0.6346 | \n","Epoch 11/50 | train | Loss: 0.7124 Acc: 0.7603 | val | Loss: 0.8935 Acc: 0.7081 | \n","Epoch 12/50 | train | Loss: 0.6697 Acc: 0.7715 | val | Loss: 0.8868 Acc: 0.7046 | \n","Epoch 13/50 | train | Loss: 0.6204 Acc: 0.7937 | val | Loss: 0.8702 Acc: 0.7220 | \n","Epoch 14/50 | train | Loss: 0.5733 Acc: 0.8072 | val | Loss: 0.9346 Acc: 0.6988 | \n","Epoch 15/50 | train | Loss: 0.5483 Acc: 0.8133 | val | Loss: 1.1992 Acc: 0.6136 | \n","Epoch 16/50 | train | Loss: 0.5080 Acc: 0.8249 | val | Loss: 0.8520 Acc: 0.7311 | \n","Epoch 17/50 | train | Loss: 0.4632 Acc: 0.8414 | val | Loss: 1.2942 Acc: 0.6148 | \n","Epoch 18/50 | train | Loss: 0.4311 Acc: 0.8542 | val | Loss: 0.7690 Acc: 0.7559 | \n","Epoch 19/50 | train | Loss: 0.3974 Acc: 0.8634 | val | Loss: 0.8545 Acc: 0.7373 | \n","Epoch 20/50 | train | Loss: 0.3672 Acc: 0.8775 | val | Loss: 1.0346 Acc: 0.7000 | \n","Epoch 21/50 | train | Loss: 0.3398 Acc: 0.8835 | val | Loss: 0.7401 Acc: 0.7733 | \n","Epoch 22/50 | train | Loss: 0.3088 Acc: 0.8952 | val | Loss: 0.9386 Acc: 0.7282 | \n","Epoch 23/50 | train | Loss: 0.2864 Acc: 0.9036 | val | Loss: 1.0606 Acc: 0.7072 | \n","Epoch 24/50 | train | Loss: 0.2545 Acc: 0.9167 | val | Loss: 0.8461 Acc: 0.7526 | \n","Epoch 25/50 | train | Loss: 0.2317 Acc: 0.9231 | val | Loss: 0.9985 Acc: 0.7225 | \n","Epoch 26/50 | train | Loss: 0.2160 Acc: 0.9288 | val | Loss: 0.7550 Acc: 0.7807 | \n","Epoch 27/50 | train | Loss: 0.2036 Acc: 0.9308 | val | Loss: 0.9936 Acc: 0.7468 | \n","Epoch 28/50 | train | Loss: 0.1828 Acc: 0.9408 | val | Loss: 0.9696 Acc: 0.7437 | \n","Epoch 29/50 | train | Loss: 0.1670 Acc: 0.9453 | val | Loss: 0.8091 Acc: 0.7776 | \n","Epoch 30/50 | train | Loss: 0.1490 Acc: 0.9517 | val | Loss: 0.8507 Acc: 0.7812 | \n","Epoch 31/50 | train | Loss: 0.1377 Acc: 0.9546 | val | Loss: 0.9083 Acc: 0.7645 | \n","Epoch 32/50 | train | Loss: 0.1274 Acc: 0.9576 | val | Loss: 1.0291 Acc: 0.7401 | \n","Epoch 33/50 | train | Loss: 0.1046 Acc: 0.9666 | val | Loss: 0.7961 Acc: 0.7960 | \n","Epoch 34/50 | train | Loss: 0.1067 Acc: 0.9638 | val | Loss: 0.8260 Acc: 0.7872 | \n","Epoch 35/50 | train | Loss: 0.0928 Acc: 0.9697 | val | Loss: 1.0201 Acc: 0.7588 | \n","Epoch 36/50 | train | Loss: 0.0922 Acc: 0.9699 | val | Loss: 0.8814 Acc: 0.7791 | \n","Epoch 37/50 | train | Loss: 0.0962 Acc: 0.9676 | val | Loss: 0.9732 Acc: 0.7581 | \n","Epoch 38/50 | train | Loss: 0.0842 Acc: 0.9735 | val | Loss: 0.9982 Acc: 0.7669 | \n","Epoch 39/50 | train | Loss: 0.0687 Acc: 0.9778 | val | Loss: 1.0744 Acc: 0.7683 | \n","Epoch 40/50 | train | Loss: 0.0613 Acc: 0.9811 | val | Loss: 0.8799 Acc: 0.7879 | \n","Epoch 41/50 | train | Loss: 0.0593 Acc: 0.9807 | val | Loss: 0.9190 Acc: 0.7848 | \n","Epoch 42/50 | train | Loss: 0.0603 Acc: 0.9801 | val | Loss: 0.8543 Acc: 0.7965 | \n","Epoch 43/50 | train | Loss: 0.0539 Acc: 0.9835 | val | Loss: 1.0184 Acc: 0.7722 | \n","Epoch 44/50 | train | Loss: 0.0618 Acc: 0.9796 | val | Loss: 0.9360 Acc: 0.7858 | \n","Epoch 45/50 | train | Loss: 0.0528 Acc: 0.9840 | val | Loss: 0.9864 Acc: 0.7872 | \n","Epoch 46/50 | train | Loss: 0.0505 Acc: 0.9842 | val | Loss: 0.9436 Acc: 0.7917 | \n","Epoch 47/50 | train | Loss: 0.0409 Acc: 0.9884 | val | Loss: 0.8411 Acc: 0.8075 | \n","Epoch 48/50 | train | Loss: 0.0410 Acc: 0.9872 | val | Loss: 0.9559 Acc: 0.7920 | \n","Epoch 49/50 | train | Loss: 0.0424 Acc: 0.9870 | val | Loss: 0.8382 Acc: 0.8073 | \n","Epoch 50/50 | train | Loss: 0.0384 Acc: 0.9887 | val | Loss: 1.0580 Acc: 0.7710 | \n","--------------------\n","K-fold: 5\n","--------------------\n","Epoch 01/50 | train | Loss: 1.9582 Acc: 0.3070 | val | Loss: 2.7445 Acc: 0.2505 | \n","Epoch 02/50 | train | Loss: 1.5697 Acc: 0.4500 | val | Loss: 2.0690 Acc: 0.3052 | \n","Epoch 03/50 | train | Loss: 1.3497 Acc: 0.5301 | val | Loss: 1.7325 Acc: 0.4387 | \n","Epoch 04/50 | train | Loss: 1.2147 Acc: 0.5795 | val | Loss: 1.2341 Acc: 0.5773 | \n","Epoch 05/50 | train | Loss: 1.1088 Acc: 0.6168 | val | Loss: 1.3944 Acc: 0.5300 | \n","Epoch 06/50 | train | Loss: 1.0145 Acc: 0.6506 | val | Loss: 1.5079 Acc: 0.4951 | \n","Epoch 07/50 | train | Loss: 0.9358 Acc: 0.6792 | val | Loss: 1.2163 Acc: 0.5828 | \n","Epoch 08/50 | train | Loss: 0.8715 Acc: 0.7003 | val | Loss: 1.0370 Acc: 0.6523 | \n","Epoch 09/50 | train | Loss: 0.8119 Acc: 0.7233 | val | Loss: 1.0653 Acc: 0.6437 | \n","Epoch 10/50 | train | Loss: 0.7639 Acc: 0.7409 | val | Loss: 1.1068 Acc: 0.6391 | \n","Epoch 11/50 | train | Loss: 0.7062 Acc: 0.7614 | val | Loss: 0.9849 Acc: 0.6797 | \n","Epoch 12/50 | train | Loss: 0.6596 Acc: 0.7745 | val | Loss: 0.9872 Acc: 0.6606 | \n","Epoch 13/50 | train | Loss: 0.6157 Acc: 0.7914 | val | Loss: 0.9650 Acc: 0.6843 | \n","Epoch 14/50 | train | Loss: 0.5727 Acc: 0.8063 | val | Loss: 0.8151 Acc: 0.7230 | \n","Epoch 15/50 | train | Loss: 0.5341 Acc: 0.8167 | val | Loss: 0.8189 Acc: 0.7313 | \n","Epoch 16/50 | train | Loss: 0.5072 Acc: 0.8280 | val | Loss: 0.8936 Acc: 0.7311 | \n","Epoch 17/50 | train | Loss: 0.4712 Acc: 0.8407 | val | Loss: 0.8882 Acc: 0.7098 | \n","Epoch 18/50 | train | Loss: 0.4199 Acc: 0.8588 | val | Loss: 1.0024 Acc: 0.6764 | \n","Epoch 19/50 | train | Loss: 0.3923 Acc: 0.8678 | val | Loss: 0.8475 Acc: 0.7418 | \n","Epoch 20/50 | train | Loss: 0.3637 Acc: 0.8754 | val | Loss: 0.7973 Acc: 0.7540 | \n","Epoch 21/50 | train | Loss: 0.3309 Acc: 0.8883 | val | Loss: 0.7851 Acc: 0.7581 | \n","Epoch 22/50 | train | Loss: 0.3042 Acc: 0.8982 | val | Loss: 0.7911 Acc: 0.7561 | \n","Epoch 23/50 | train | Loss: 0.2833 Acc: 0.9050 | val | Loss: 0.9668 Acc: 0.7308 | \n","Epoch 24/50 | train | Loss: 0.2473 Acc: 0.9178 | val | Loss: 1.0132 Acc: 0.7258 | \n","Epoch 25/50 | train | Loss: 0.2378 Acc: 0.9185 | val | Loss: 0.9295 Acc: 0.7313 | \n","Epoch 26/50 | train | Loss: 0.2161 Acc: 0.9283 | val | Loss: 0.8951 Acc: 0.7554 | \n","Epoch 27/50 | train | Loss: 0.1890 Acc: 0.9387 | val | Loss: 0.9159 Acc: 0.7499 | \n","Epoch 28/50 | train | Loss: 0.1705 Acc: 0.9440 | val | Loss: 0.8662 Acc: 0.7571 | \n","Epoch 29/50 | train | Loss: 0.1516 Acc: 0.9505 | val | Loss: 0.8287 Acc: 0.7631 | \n","Epoch 30/50 | train | Loss: 0.1418 Acc: 0.9524 | val | Loss: 0.8550 Acc: 0.7722 | \n","Epoch 31/50 | train | Loss: 0.1331 Acc: 0.9573 | val | Loss: 0.9688 Acc: 0.7538 | \n","Epoch 32/50 | train | Loss: 0.1141 Acc: 0.9642 | val | Loss: 0.8591 Acc: 0.7731 | \n","Epoch 33/50 | train | Loss: 0.1252 Acc: 0.9583 | val | Loss: 0.8908 Acc: 0.7674 | \n","Epoch 34/50 | train | Loss: 0.1065 Acc: 0.9665 | val | Loss: 1.0839 Acc: 0.7404 | \n","Epoch 35/50 | train | Loss: 0.0874 Acc: 0.9718 | val | Loss: 0.8515 Acc: 0.7886 | \n","Epoch 36/50 | train | Loss: 0.0933 Acc: 0.9695 | val | Loss: 0.9429 Acc: 0.7738 | \n","Epoch 37/50 | train | Loss: 0.0819 Acc: 0.9741 | val | Loss: 1.0030 Acc: 0.7487 | \n","Epoch 38/50 | train | Loss: 0.0760 Acc: 0.9761 | val | Loss: 0.9501 Acc: 0.7607 | \n","Epoch 39/50 | train | Loss: 0.0706 Acc: 0.9779 | val | Loss: 0.7627 Acc: 0.8030 | \n","Epoch 40/50 | train | Loss: 0.0688 Acc: 0.9792 | val | Loss: 0.8039 Acc: 0.8068 | \n","Epoch 41/50 | train | Loss: 0.0611 Acc: 0.9813 | val | Loss: 1.2149 Acc: 0.7468 | \n","Epoch 42/50 | train | Loss: 0.0684 Acc: 0.9774 | val | Loss: 0.9955 Acc: 0.7719 | \n","Epoch 43/50 | train | Loss: 0.0533 Acc: 0.9838 | val | Loss: 0.9348 Acc: 0.7860 | \n","Epoch 44/50 | train | Loss: 0.0592 Acc: 0.9813 | val | Loss: 1.1919 Acc: 0.7265 | \n","Epoch 45/50 | train | Loss: 0.0502 Acc: 0.9850 | val | Loss: 0.9320 Acc: 0.7910 | \n","Epoch 46/50 | train | Loss: 0.0400 Acc: 0.9885 | val | Loss: 0.8819 Acc: 0.7867 | \n","Epoch 47/50 | train | Loss: 0.0431 Acc: 0.9870 | val | Loss: 0.8950 Acc: 0.7944 | \n","Epoch 48/50 | train | Loss: 0.0380 Acc: 0.9882 | val | Loss: 0.7995 Acc: 0.8058 | \n","Epoch 49/50 | train | Loss: 0.0355 Acc: 0.9896 | val | Loss: 0.8384 Acc: 0.8092 | \n","Epoch 50/50 | train | Loss: 0.0346 Acc: 0.9894 | val | Loss: 0.8324 Acc: 0.8099 | \n"]}],"source":["kf = StratifiedKFold(n_splits=5)\n","foldperf={}\n","save_path = '/content/drive/MyDrive/DL_study_179/weight/week2/'\n","for i, (train_index, val_index) in enumerate(kf.split(train_dataset, train_dataset.targets)):\n","\n","    pretrained_model=models.resnet18(pretrained=False)\n","    pretrained_model.fc = nn.Linear(512, 10)\n","\n","    # optimizer = optim.Adam(pretrained_model.parameters(), lr=0.001)\n","    optimizer = optim.SGD(pretrained_model.parameters(), lr=0.001, momentum=0.9)\n","    criterion = nn.CrossEntropyLoss().to(device)\n","\n","    # print(\"train_index : {}, val_index : {}\".format(len(train_index), len(val_index)))\n","    train = torch.utils.data.Subset(train_dataset, train_index)\n","    valid = torch.utils.data.Subset(train_dataset, val_index)\n","\n","\n","    trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","    validloader = torch.utils.data.DataLoader(valid, batch_size=batch_size)\n","    \n","    \n","    dataloaders_dict = {\"train\" : trainloader, \"val\": validloader}\n","    \n","    print('-' * 20)\n","    print('K-fold: {}'.format(i+1))\n","    print('-' * 20)\n","    history = train_model(pretrained_model, dataloaders_dict, criterion, optimizer, i+1, num_epochs, save_path)\n","\n","    foldperf['fold{}'.format(i+1)] = history\n"]},{"cell_type":"markdown","source":["```\n","K-fold: 1\n","--------------------\n","Epoch 1/50\n","train Loss: 2.1141 Acc: 0.2407 | val Loss: 2.0615 Acc: 0.2782 | \n","--------------------\n","Epoch 2/50\n","train Loss: 1.9370 Acc: 0.3307 | val Loss: 1.8876 Acc: 0.3629 | \n","--------------------\n","Epoch 3/50\n","train Loss: 1.7692 Acc: 0.3926 | val Loss: 1.9969 Acc: 0.3080 | \n","--------------------\n","Epoch 4/50\n","train Loss: 1.6109 Acc: 0.4381 | val Loss: 1.9710 Acc: 0.3615 | \n","--------------------\n","Epoch 5/50\n","train Loss: 1.4896 Acc: 0.4869 | val Loss: 1.7555 Acc: 0.4160 | \n","--------------------\n","Epoch 6/50\n","train Loss: 1.4026 Acc: 0.5177 | val Loss: 1.9030 Acc: 0.3505 | \n","--------------------\n","Epoch 7/50\n","train Loss: 1.3278 Acc: 0.5448 | val Loss: 1.6967 Acc: 0.4417 | \n","--------------------\n","Epoch 8/50\n","train Loss: 1.2489 Acc: 0.5710 | val Loss: 2.3915 Acc: 0.2870 | \n","--------------------\n","Epoch 9/50\n","train Loss: 1.1848 Acc: 0.5927 | val Loss: 2.1828 Acc: 0.4014 | \n","--------------------\n","Epoch 10/50\n","train Loss: 1.1319 Acc: 0.6133 | val Loss: 1.2749 Acc: 0.5712 | \n","--------------------\n","Epoch 11/50\n","train Loss: 1.0838 Acc: 0.6276 | val Loss: 1.3177 Acc: 0.5535 | \n","--------------------\n","Epoch 12/50\n","train Loss: 1.0457 Acc: 0.6398 | val Loss: 1.1717 Acc: 0.6020 | \n","--------------------\n","Epoch 13/50\n","train Loss: 1.0057 Acc: 0.6564 | val Loss: 2.0977 Acc: 0.4317 | \n","--------------------\n","Epoch 14/50\n","train Loss: 0.9693 Acc: 0.6723 | val Loss: 1.2087 Acc: 0.5786 | \n","--------------------\n","Epoch 15/50\n","train Loss: 0.9335 Acc: 0.6853 | val Loss: 1.1028 Acc: 0.6201 | \n","--------------------\n","Epoch 16/50\n","train Loss: 0.9035 Acc: 0.6946 | val Loss: 1.4425 Acc: 0.5420 | \n","--------------------\n","Epoch 17/50\n","train Loss: 0.8722 Acc: 0.7016 | val Loss: 1.8395 Acc: 0.4807 | \n","--------------------\n","Epoch 18/50\n","train Loss: 0.8439 Acc: 0.7161 | val Loss: 1.2424 Acc: 0.5862 | \n","--------------------\n","Epoch 19/50\n","train Loss: 0.8169 Acc: 0.7216 | val Loss: 1.1347 Acc: 0.6246 | \n","--------------------\n","Epoch 20/50\n","train Loss: 0.7832 Acc: 0.7354 | val Loss: 1.2746 Acc: 0.5883 | \n","--------------------\n","Epoch 21/50\n","train Loss: 0.7651 Acc: 0.7389 | val Loss: 1.0693 Acc: 0.6464 | \n","--------------------\n","Epoch 22/50\n","train Loss: 0.7287 Acc: 0.7527 | val Loss: 1.2804 Acc: 0.6089 | \n","--------------------\n","Epoch 23/50\n","train Loss: 0.7064 Acc: 0.7604 | val Loss: 0.9876 Acc: 0.6741 | \n","--------------------\n","Epoch 24/50\n","train Loss: 0.6818 Acc: 0.7710 | val Loss: 1.2249 Acc: 0.6067 | \n","--------------------\n","Epoch 25/50\n","train Loss: 0.6626 Acc: 0.7799 | val Loss: 1.0827 Acc: 0.6507 | \n","--------------------\n","Epoch 26/50\n","train Loss: 0.6396 Acc: 0.7823 | val Loss: 1.6169 Acc: 0.5241 | \n","--------------------\n","Epoch 27/50\n","train Loss: 0.6188 Acc: 0.7893 | val Loss: 2.8962 Acc: 0.3383 | \n","--------------------\n","Epoch 28/50\n","train Loss: 0.5990 Acc: 0.7970 | val Loss: 0.9806 Acc: 0.6822 | \n","--------------------\n","Epoch 29/50\n","train Loss: 0.5776 Acc: 0.8038 | val Loss: 1.2127 Acc: 0.6511 | \n","--------------------\n","Epoch 30/50\n","train Loss: 0.5475 Acc: 0.8152 | val Loss: 1.5424 Acc: 0.5513 | \n","--------------------\n","Epoch 31/50\n","train Loss: 0.5444 Acc: 0.8147 | val Loss: 1.0913 Acc: 0.6459 | \n","--------------------\n","Epoch 32/50\n","train Loss: 0.5133 Acc: 0.8266 | val Loss: 1.0569 Acc: 0.6798 | \n","--------------------\n","Epoch 33/50\n","train Loss: 0.4917 Acc: 0.8337 | val Loss: 0.8818 Acc: 0.7137 | \n","--------------------\n","Epoch 34/50\n","train Loss: 0.4846 Acc: 0.8386 | val Loss: 0.9608 Acc: 0.7089 | \n","--------------------\n","Epoch 35/50\n","train Loss: 0.4552 Acc: 0.8479 | val Loss: 0.9589 Acc: 0.7111 | \n","--------------------\n","Epoch 36/50\n","train Loss: 0.4474 Acc: 0.8507 | val Loss: 1.4708 Acc: 0.6103 | \n","--------------------\n","Epoch 37/50\n","train Loss: 0.4182 Acc: 0.8590 | val Loss: 1.3710 Acc: 0.5941 | \n","--------------------\n","Epoch 38/50\n","train Loss: 0.4022 Acc: 0.8679 | val Loss: 0.9928 Acc: 0.6989 | \n","--------------------\n","Epoch 39/50\n","train Loss: 0.3908 Acc: 0.8699 | val Loss: 0.9662 Acc: 0.7006 | \n","--------------------\n","Epoch 40/50\n","train Loss: 0.3755 Acc: 0.8771 | val Loss: 1.1018 Acc: 0.6619 | \n","--------------------\n","Epoch 41/50\n","train Loss: 0.3527 Acc: 0.8822 | val Loss: 0.9382 Acc: 0.7242 | \n","--------------------\n","Epoch 42/50\n","train Loss: 0.3400 Acc: 0.8894 | val Loss: 0.9068 Acc: 0.7199 | \n","--------------------\n","Epoch 43/50\n","train Loss: 0.3316 Acc: 0.8883 | val Loss: 1.0945 Acc: 0.6831 | \n","--------------------\n","Epoch 44/50\n","train Loss: 0.3222 Acc: 0.8913 | val Loss: 1.1410 Acc: 0.6855 | \n","--------------------\n","Epoch 45/50\n","train Loss: 0.2987 Acc: 0.9003 | val Loss: 0.8974 Acc: 0.7304 | \n","--------------------\n","Epoch 46/50\n","train Loss: 0.2775 Acc: 0.9080 | val Loss: 1.2858 Acc: 0.6430 | \n","--------------------\n","Epoch 47/50\n","train Loss: 0.2871 Acc: 0.9051 | val Loss: 1.3260 Acc: 0.6495 | \n","--------------------\n","Epoch 48/50\n","train Loss: 0.2563 Acc: 0.9159 | val Loss: 0.9723 Acc: 0.7027 | \n","--------------------\n","Epoch 49/50\n","train Loss: 0.2417 Acc: 0.9223 | val Loss: 1.1291 Acc: 0.6879 | \n","--------------------\n","Epoch 50/50\n","train Loss: 0.2293 Acc: 0.9260 | val Loss: 0.9446 Acc: 0.7316 | \n","K-fold: 2\n","--------------------\n","Epoch 1/50\n","train Loss: 2.0911 Acc: 0.2472 | val Loss: 2.0624 Acc: 0.2622 | \n","--------------------\n","Epoch 2/50\n","train Loss: 1.9402 Acc: 0.3196 | val Loss: 1.9495 Acc: 0.3214 | \n","--------------------\n","Epoch 3/50\n","train Loss: 1.7894 Acc: 0.3786 | val Loss: 2.0433 Acc: 0.2851 | \n","--------------------\n","Epoch 4/50\n","train Loss: 1.6406 Acc: 0.4284 | val Loss: 2.0752 Acc: 0.3197 | \n","--------------------\n","Epoch 5/50\n","train Loss: 1.5120 Acc: 0.4722 | val Loss: 2.4122 Acc: 0.2875 | \n","--------------------\n","Epoch 6/50\n","train Loss: 1.4254 Acc: 0.5057 | val Loss: 2.4833 Acc: 0.3004 | \n","--------------------\n","Epoch 7/50\n","train Loss: 1.3403 Acc: 0.5354 | val Loss: 2.3724 Acc: 0.3436 | \n","--------------------\n","Epoch 8/50\n","train Loss: 1.2619 Acc: 0.5653 | val Loss: 2.2456 Acc: 0.3546 | \n","--------------------\n","Epoch 9/50\n","train Loss: 1.2084 Acc: 0.5844 | val Loss: 1.8814 Acc: 0.3613 | \n","--------------------\n","Epoch 10/50\n","train Loss: 1.1555 Acc: 0.6016 | val Loss: 1.4700 Acc: 0.5158 | \n","--------------------\n","Epoch 11/50\n","train Loss: 1.1092 Acc: 0.6184 | val Loss: 1.2563 Acc: 0.5664 | \n","--------------------\n","Epoch 12/50\n","train Loss: 1.0616 Acc: 0.6356 | val Loss: 1.2416 Acc: 0.5814 | \n","--------------------\n","Epoch 13/50\n","train Loss: 1.0126 Acc: 0.6504 | val Loss: 1.1708 Acc: 0.6122 | \n","--------------------\n","Epoch 14/50\n","train Loss: 0.9763 Acc: 0.6632 | val Loss: 2.1385 Acc: 0.4081 | \n","--------------------\n","Epoch 15/50\n","train Loss: 0.9433 Acc: 0.6719 | val Loss: 1.3222 Acc: 0.5707 | \n","--------------------\n","Epoch 16/50\n","train Loss: 0.9083 Acc: 0.6856 | val Loss: 1.7453 Acc: 0.4783 | \n","--------------------\n","Epoch 17/50\n","train Loss: 0.8835 Acc: 0.6965 | val Loss: 1.2496 Acc: 0.5819 | \n","--------------------\n","Epoch 18/50\n","train Loss: 0.8497 Acc: 0.7080 | val Loss: 1.1913 Acc: 0.6113 | \n","--------------------\n","Epoch 19/50\n","train Loss: 0.8236 Acc: 0.7155 | val Loss: 1.3169 Acc: 0.5917 | \n","--------------------\n","Epoch 20/50\n","train Loss: 0.7899 Acc: 0.7316 | val Loss: 1.3586 Acc: 0.5745 | \n","--------------------\n","Epoch 21/50\n","train Loss: 0.7640 Acc: 0.7400 | val Loss: 1.0320 Acc: 0.6650 | \n","--------------------\n","Epoch 22/50\n","train Loss: 0.7423 Acc: 0.7476 | val Loss: 1.5696 Acc: 0.5368 | \n","--------------------\n","Epoch 23/50\n","train Loss: 0.7304 Acc: 0.7524 | val Loss: 1.1102 Acc: 0.6332 | \n","--------------------\n","Epoch 24/50\n","train Loss: 0.6985 Acc: 0.7639 | val Loss: 1.1083 Acc: 0.6356 | \n","--------------------\n","Epoch 25/50\n","train Loss: 0.6690 Acc: 0.7752 | val Loss: 1.0735 Acc: 0.6550 | \n","--------------------\n","Epoch 26/50\n","train Loss: 0.6484 Acc: 0.7755 | val Loss: 1.0981 Acc: 0.6557 | \n","--------------------\n","Epoch 27/50\n","train Loss: 0.6245 Acc: 0.7884 | val Loss: 1.0568 Acc: 0.6619 | \n","--------------------\n","Epoch 28/50\n","train Loss: 0.6095 Acc: 0.7948 | val Loss: 0.8775 Acc: 0.7056 | \n","--------------------\n","Epoch 29/50\n","train Loss: 0.5812 Acc: 0.8048 | val Loss: 1.2685 Acc: 0.6096 | \n","--------------------\n","Epoch 30/50\n","train Loss: 0.5642 Acc: 0.8101 | val Loss: 0.9976 Acc: 0.6741 | \n","--------------------\n","Epoch 31/50\n","train Loss: 0.5512 Acc: 0.8153 | val Loss: 0.8996 Acc: 0.7058 | \n","--------------------\n","Epoch 32/50\n","train Loss: 0.5371 Acc: 0.8161 | val Loss: 1.1177 Acc: 0.6609 | \n","--------------------\n","Epoch 33/50\n","train Loss: 0.5040 Acc: 0.8339 | val Loss: 1.7764 Acc: 0.5093 | \n","--------------------\n","Epoch 34/50\n","train Loss: 0.4858 Acc: 0.8360 | val Loss: 0.8053 Acc: 0.7414 | \n","--------------------\n","Epoch 35/50\n","train Loss: 0.4725 Acc: 0.8398 | val Loss: 0.9264 Acc: 0.6996 | \n","--------------------\n","Epoch 36/50\n","train Loss: 0.4511 Acc: 0.8501 | val Loss: 1.0747 Acc: 0.6812 | \n","--------------------\n","Epoch 37/50\n","train Loss: 0.4383 Acc: 0.8552 | val Loss: 0.9726 Acc: 0.6877 | \n","--------------------\n","Epoch 38/50\n","train Loss: 0.4173 Acc: 0.8620 | val Loss: 1.2748 Acc: 0.6239 | \n","--------------------\n","Epoch 39/50\n","train Loss: 0.4070 Acc: 0.8633 | val Loss: 1.0912 Acc: 0.6693 | \n","--------------------\n","Epoch 40/50\n","train Loss: 0.3903 Acc: 0.8717 | val Loss: 0.7971 Acc: 0.7407 | \n","--------------------\n","Epoch 41/50\n","train Loss: 0.3668 Acc: 0.8768 | val Loss: 1.0355 Acc: 0.6994 | \n","--------------------\n","Epoch 42/50\n","train Loss: 0.3534 Acc: 0.8810 | val Loss: 1.2629 Acc: 0.6583 | \n","--------------------\n","Epoch 43/50\n","train Loss: 0.3336 Acc: 0.8900 | val Loss: 1.4349 Acc: 0.6349 | \n","--------------------\n","Epoch 44/50\n","train Loss: 0.3220 Acc: 0.8957 | val Loss: 0.9484 Acc: 0.7128 | \n","--------------------\n","Epoch 45/50\n","train Loss: 0.3148 Acc: 0.8960 | val Loss: 1.1058 Acc: 0.6984 | \n","--------------------\n","Epoch 46/50\n","train Loss: 0.2880 Acc: 0.9078 | val Loss: 0.8880 Acc: 0.7278 | \n","--------------------\n","Epoch 47/50\n","train Loss: 0.2727 Acc: 0.9118 | val Loss: 1.2302 Acc: 0.6545 | \n","--------------------\n","Epoch 48/50\n","train Loss: 0.2695 Acc: 0.9115 | val Loss: 0.9366 Acc: 0.7342 | \n","--------------------\n","Epoch 49/50\n","train Loss: 0.2488 Acc: 0.9184 | val Loss: 0.9722 Acc: 0.7073 | \n","--------------------\n","Epoch 50/50\n","train Loss: 0.2379 Acc: 0.9228 | val Loss: 1.0056 Acc: 0.7182 | \n","K-fold: 3\n","--------------------\n","Epoch 1/50\n","train Loss: 2.0915 Acc: 0.2433 | val Loss: 2.0342 Acc: 0.2758 | \n","--------------------\n","Epoch 2/50\n","train Loss: 1.9191 Acc: 0.3272 | val Loss: 2.0557 Acc: 0.3102 | \n","--------------------\n","Epoch 3/50\n","train Loss: 1.7653 Acc: 0.3925 | val Loss: 2.1044 Acc: 0.3462 | \n","--------------------\n","Epoch 4/50\n","train Loss: 1.6270 Acc: 0.4304 | val Loss: 1.6914 Acc: 0.3830 | \n","--------------------\n","Epoch 5/50\n","train Loss: 1.5207 Acc: 0.4704 | val Loss: 4.0290 Acc: 0.1817 | \n","--------------------\n","Epoch 6/50\n","train Loss: 1.4330 Acc: 0.5007 | val Loss: 1.6667 Acc: 0.4281 | \n","--------------------\n","Epoch 7/50\n","train Loss: 1.3540 Acc: 0.5284 | val Loss: 2.0015 Acc: 0.3567 | \n","--------------------\n","Epoch 8/50\n","train Loss: 1.2804 Acc: 0.5564 | val Loss: 1.5555 Acc: 0.4776 | \n","--------------------\n","Epoch 9/50\n","train Loss: 1.2175 Acc: 0.5781 | val Loss: 1.3241 Acc: 0.5392 | \n","--------------------\n","Epoch 10/50\n","train Loss: 1.1699 Acc: 0.5958 | val Loss: 1.9512 Acc: 0.4040 | \n","--------------------\n","Epoch 11/50\n","train Loss: 1.1229 Acc: 0.6130 | val Loss: 1.6157 Acc: 0.4897 | \n","--------------------\n","Epoch 12/50\n","train Loss: 1.0736 Acc: 0.6305 | val Loss: 1.2615 Acc: 0.5755 | \n","--------------------\n","Epoch 13/50\n","train Loss: 1.0286 Acc: 0.6463 | val Loss: 1.3532 Acc: 0.5349 | \n","--------------------\n","Epoch 14/50\n","train Loss: 1.0002 Acc: 0.6607 | val Loss: 1.1657 Acc: 0.6058 | \n","--------------------\n","Epoch 15/50\n","train Loss: 0.9642 Acc: 0.6673 | val Loss: 1.3594 Acc: 0.5774 | \n","--------------------\n","Epoch 16/50\n","train Loss: 0.9345 Acc: 0.6793 | val Loss: 1.2961 Acc: 0.5714 | \n","--------------------\n","Epoch 17/50\n","train Loss: 0.9024 Acc: 0.6910 | val Loss: 1.7947 Acc: 0.4441 | \n","--------------------\n","Epoch 18/50\n","train Loss: 0.8679 Acc: 0.7016 | val Loss: 1.0004 Acc: 0.6502 | \n","--------------------\n","Epoch 19/50\n","train Loss: 0.8379 Acc: 0.7133 | val Loss: 0.9852 Acc: 0.6676 | \n","--------------------\n","Epoch 20/50\n","train Loss: 0.8186 Acc: 0.7220 | val Loss: 2.5306 Acc: 0.4742 | \n","--------------------\n","Epoch 21/50\n","train Loss: 0.7901 Acc: 0.7316 | val Loss: 1.1066 Acc: 0.6337 | \n","--------------------\n","Epoch 22/50\n","train Loss: 0.7552 Acc: 0.7429 | val Loss: 1.3309 Acc: 0.5774 | \n","--------------------\n","Epoch 23/50\n","train Loss: 0.7395 Acc: 0.7481 | val Loss: 0.9918 Acc: 0.6636 | \n","--------------------\n","Epoch 24/50\n","train Loss: 0.7206 Acc: 0.7541 | val Loss: 0.9224 Acc: 0.6927 | \n","--------------------\n","Epoch 25/50\n","train Loss: 0.6847 Acc: 0.7679 | val Loss: 1.0997 Acc: 0.6497 | \n","--------------------\n","Epoch 26/50\n","train Loss: 0.6744 Acc: 0.7708 | val Loss: 0.8823 Acc: 0.6939 | \n","--------------------\n","Epoch 27/50\n","train Loss: 0.6532 Acc: 0.7795 | val Loss: 1.5038 Acc: 0.5690 | \n","--------------------\n","Epoch 28/50\n","train Loss: 0.6226 Acc: 0.7879 | val Loss: 1.0550 Acc: 0.6519 | \n","--------------------\n","Epoch 29/50\n","train Loss: 0.6030 Acc: 0.7973 | val Loss: 1.1349 Acc: 0.6459 | \n","--------------------\n","Epoch 30/50\n","train Loss: 0.5786 Acc: 0.8059 | val Loss: 1.0555 Acc: 0.6559 | \n","--------------------\n","Epoch 31/50\n","train Loss: 0.5634 Acc: 0.8085 | val Loss: 1.1800 Acc: 0.6337 | \n","--------------------\n","Epoch 32/50\n","train Loss: 0.5477 Acc: 0.8120 | val Loss: 1.5109 Acc: 0.6108 | \n","--------------------\n","Epoch 33/50\n","train Loss: 0.5277 Acc: 0.8214 | val Loss: 0.9697 Acc: 0.6913 | \n","--------------------\n","Epoch 34/50\n","train Loss: 0.5007 Acc: 0.8356 | val Loss: 1.3451 Acc: 0.5895 | \n","--------------------\n","Epoch 35/50\n","train Loss: 0.4856 Acc: 0.8346 | val Loss: 0.9453 Acc: 0.6953 | \n","--------------------\n","Epoch 36/50\n","train Loss: 0.4704 Acc: 0.8380 | val Loss: 0.9809 Acc: 0.6951 | \n","--------------------\n","Epoch 37/50\n","train Loss: 0.4580 Acc: 0.8462 | val Loss: 0.9676 Acc: 0.7018 | \n","--------------------\n","Epoch 38/50\n","train Loss: 0.4258 Acc: 0.8558 | val Loss: 0.8255 Acc: 0.7314 | \n","--------------------\n","Epoch 39/50\n","train Loss: 0.4168 Acc: 0.8589 | val Loss: 1.1859 Acc: 0.6380 | \n","--------------------\n","Epoch 40/50\n","train Loss: 0.4004 Acc: 0.8638 | val Loss: 0.9315 Acc: 0.7144 | \n","--------------------\n","Epoch 41/50\n","train Loss: 0.3749 Acc: 0.8772 | val Loss: 0.9903 Acc: 0.6982 | \n","--------------------\n","Epoch 42/50\n","train Loss: 0.3746 Acc: 0.8728 | val Loss: 0.9229 Acc: 0.7104 | \n","--------------------\n","Epoch 43/50\n","train Loss: 0.3439 Acc: 0.8834 | val Loss: 0.9547 Acc: 0.7170 | \n","--------------------\n","Epoch 44/50\n","train Loss: 0.3303 Acc: 0.8887 | val Loss: 0.9818 Acc: 0.6963 | \n","--------------------\n","Epoch 45/50\n","train Loss: 0.3104 Acc: 0.8974 | val Loss: 1.0007 Acc: 0.7065 | \n","--------------------\n","Epoch 46/50\n","train Loss: 0.2946 Acc: 0.9040 | val Loss: 1.2581 Acc: 0.6428 | \n","--------------------\n","Epoch 47/50\n","train Loss: 0.2864 Acc: 0.9078 | val Loss: 1.0562 Acc: 0.6929 | \n","--------------------\n","Epoch 48/50\n","train Loss: 0.2717 Acc: 0.9108 | val Loss: 1.5415 Acc: 0.6137 | \n","--------------------\n","Epoch 49/50\n","train Loss: 0.2632 Acc: 0.9145 | val Loss: 1.0706 Acc: 0.6963 | \n","--------------------\n","Epoch 50/50\n","train Loss: 0.2445 Acc: 0.9198 | val Loss: 0.9569 Acc: 0.7242 | \n","K-fold: 4\n","--------------------\n","Epoch 1/50\n","train Loss: 2.1116 Acc: 0.2360 | val Loss: 2.0362 Acc: 0.2749 | \n","--------------------\n","Epoch 2/50\n","train Loss: 1.9465 Acc: 0.3217 | val Loss: 1.9038 Acc: 0.3303 | \n","--------------------\n","Epoch 3/50\n","train Loss: 1.7742 Acc: 0.3821 | val Loss: 1.7218 Acc: 0.3969 | \n","--------------------\n","Epoch 4/50\n","train Loss: 1.6152 Acc: 0.4387 | val Loss: 2.2487 Acc: 0.3110 | \n","--------------------\n","Epoch 5/50\n","train Loss: 1.4987 Acc: 0.4767 | val Loss: 1.7417 Acc: 0.3955 | \n","--------------------\n","Epoch 6/50\n","train Loss: 1.4220 Acc: 0.5030 | val Loss: 2.2677 Acc: 0.3449 | \n","--------------------\n","Epoch 7/50\n","train Loss: 1.3474 Acc: 0.5311 | val Loss: 1.3898 Acc: 0.5090 | \n","--------------------\n","Epoch 8/50\n","train Loss: 1.2757 Acc: 0.5608 | val Loss: 1.5942 Acc: 0.4784 | \n","--------------------\n","Epoch 9/50\n","train Loss: 1.2207 Acc: 0.5807 | val Loss: 2.3200 Acc: 0.3523 | \n","--------------------\n","Epoch 10/50\n","train Loss: 1.1437 Acc: 0.6114 | val Loss: 1.2353 Acc: 0.5639 | \n","--------------------\n","Epoch 11/50\n","train Loss: 1.0920 Acc: 0.6279 | val Loss: 2.6120 Acc: 0.3463 | \n","--------------------\n","Epoch 12/50\n","train Loss: 1.0479 Acc: 0.6422 | val Loss: 1.8040 Acc: 0.4471 | \n","--------------------\n","Epoch 13/50\n","train Loss: 1.0016 Acc: 0.6569 | val Loss: 1.2221 Acc: 0.5787 | \n","--------------------\n","Epoch 14/50\n","train Loss: 0.9670 Acc: 0.6682 | val Loss: 1.2159 Acc: 0.5890 | \n","--------------------\n","Epoch 15/50\n","train Loss: 0.9299 Acc: 0.6854 | val Loss: 1.5956 Acc: 0.4970 | \n","--------------------\n","Epoch 16/50\n","train Loss: 0.8880 Acc: 0.6973 | val Loss: 1.3658 Acc: 0.5555 | \n","--------------------\n","Epoch 17/50\n","train Loss: 0.8598 Acc: 0.7044 | val Loss: 2.0463 Acc: 0.4426 | \n","--------------------\n","Epoch 18/50\n","train Loss: 0.8295 Acc: 0.7195 | val Loss: 1.3719 Acc: 0.5713 | \n","--------------------\n","Epoch 19/50\n","train Loss: 0.8020 Acc: 0.7254 | val Loss: 1.1199 Acc: 0.6164 | \n","--------------------\n","Epoch 20/50\n","train Loss: 0.7907 Acc: 0.7279 | val Loss: 1.2175 Acc: 0.6050 | \n","--------------------\n","Epoch 21/50\n","train Loss: 0.7462 Acc: 0.7460 | val Loss: 1.3422 Acc: 0.5596 | \n","--------------------\n","Epoch 22/50\n","train Loss: 0.7161 Acc: 0.7577 | val Loss: 1.8162 Acc: 0.4528 | \n","--------------------\n","Epoch 23/50\n","train Loss: 0.6976 Acc: 0.7653 | val Loss: 2.2366 Acc: 0.4485 | \n","--------------------\n","Epoch 24/50\n","train Loss: 0.6837 Acc: 0.7712 | val Loss: 1.0084 Acc: 0.6733 | \n","--------------------\n","Epoch 25/50\n","train Loss: 0.6516 Acc: 0.7807 | val Loss: 0.9568 Acc: 0.6802 | \n","--------------------\n","Epoch 26/50\n","train Loss: 0.6316 Acc: 0.7856 | val Loss: 1.0925 Acc: 0.6642 | \n","--------------------\n","Epoch 27/50\n","train Loss: 0.6097 Acc: 0.7937 | val Loss: 1.5417 Acc: 0.5734 | \n","--------------------\n","Epoch 28/50\n","train Loss: 0.5790 Acc: 0.8053 | val Loss: 1.9950 Acc: 0.4824 | \n","--------------------\n","Epoch 29/50\n","train Loss: 0.5598 Acc: 0.8093 | val Loss: 0.8498 Acc: 0.7153 | \n","--------------------\n","Epoch 30/50\n","train Loss: 0.5441 Acc: 0.8188 | val Loss: 1.0277 Acc: 0.6709 | \n","--------------------\n","Epoch 31/50\n","train Loss: 0.5219 Acc: 0.8247 | val Loss: 1.0655 Acc: 0.6642 | \n","--------------------\n","Epoch 32/50\n","train Loss: 0.5132 Acc: 0.8288 | val Loss: 1.1678 Acc: 0.6530 | \n","--------------------\n","Epoch 33/50\n","train Loss: 0.4963 Acc: 0.8331 | val Loss: 1.3316 Acc: 0.6097 | \n","--------------------\n","Epoch 34/50\n","train Loss: 0.4873 Acc: 0.8348 | val Loss: 1.2965 Acc: 0.6253 | \n","--------------------\n","Epoch 35/50\n","train Loss: 0.4632 Acc: 0.8462 | val Loss: 1.3630 Acc: 0.6112 | \n","--------------------\n","Epoch 36/50\n","train Loss: 0.4390 Acc: 0.8538 | val Loss: 0.9307 Acc: 0.6909 | \n","--------------------\n","Epoch 37/50\n","train Loss: 0.4188 Acc: 0.8600 | val Loss: 1.0730 Acc: 0.6828 | \n","--------------------\n","Epoch 38/50\n","train Loss: 0.4051 Acc: 0.8634 | val Loss: 0.8377 Acc: 0.7339 | \n","--------------------\n","Epoch 39/50\n","train Loss: 0.4011 Acc: 0.8675 | val Loss: 1.3203 Acc: 0.6310 | \n","--------------------\n","Epoch 40/50\n","train Loss: 0.3716 Acc: 0.8762 | val Loss: 1.0644 Acc: 0.6895 | \n","--------------------\n","Epoch 41/50\n","train Loss: 0.3613 Acc: 0.8795 | val Loss: 1.2499 Acc: 0.6465 | \n","--------------------\n","Epoch 42/50\n","train Loss: 0.3443 Acc: 0.8850 | val Loss: 1.0566 Acc: 0.6912 | \n","--------------------\n","Epoch 43/50\n","train Loss: 0.3301 Acc: 0.8909 | val Loss: 0.9949 Acc: 0.7007 | \n","--------------------\n","Epoch 44/50\n","train Loss: 0.3253 Acc: 0.8900 | val Loss: 1.1094 Acc: 0.6921 | \n","--------------------\n","Epoch 45/50\n","train Loss: 0.3023 Acc: 0.9014 | val Loss: 1.0236 Acc: 0.6995 | \n","--------------------\n","Epoch 46/50\n","train Loss: 0.2936 Acc: 0.9031 | val Loss: 0.9056 Acc: 0.7277 | \n","--------------------\n","Epoch 47/50\n","train Loss: 0.2777 Acc: 0.9105 | val Loss: 1.1064 Acc: 0.6730 | \n","--------------------\n","Epoch 48/50\n","train Loss: 0.2632 Acc: 0.9134 | val Loss: 0.8953 Acc: 0.7244 | \n","--------------------\n","Epoch 49/50\n","train Loss: 0.2493 Acc: 0.9173 | val Loss: 0.9077 Acc: 0.7327 | \n","--------------------\n","Epoch 50/50\n","train Loss: 0.2398 Acc: 0.9243 | val Loss: 1.0250 Acc: 0.7077 | \n","K-fold: 5\n","--------------------\n","Epoch 1/50\n","train Loss: 2.1201 Acc: 0.2301 | val Loss: 2.0575 Acc: 0.2933 | \n","--------------------\n","Epoch 2/50\n","train Loss: 1.9513 Acc: 0.3180 | val Loss: 1.9541 Acc: 0.3091 | \n","--------------------\n","Epoch 3/50\n","train Loss: 1.7839 Acc: 0.3788 | val Loss: 1.8394 Acc: 0.3580 | \n","--------------------\n","Epoch 4/50\n","train Loss: 1.6304 Acc: 0.4288 | val Loss: 2.2048 Acc: 0.2630 | \n","--------------------\n","Epoch 5/50\n","train Loss: 1.5169 Acc: 0.4682 | val Loss: 1.7093 Acc: 0.4149 | \n","--------------------\n","Epoch 6/50\n","train Loss: 1.4174 Acc: 0.5054 | val Loss: 1.8492 Acc: 0.3735 | \n","--------------------\n","Epoch 7/50\n","train Loss: 1.3358 Acc: 0.5326 | val Loss: 1.5862 Acc: 0.4643 | \n","--------------------\n","Epoch 8/50\n","train Loss: 1.2643 Acc: 0.5590 | val Loss: 3.1583 Acc: 0.2911 | \n","--------------------\n","Epoch 9/50\n","train Loss: 1.1979 Acc: 0.5864 | val Loss: 2.3848 Acc: 0.3088 | \n","--------------------\n","Epoch 10/50\n","train Loss: 1.1447 Acc: 0.6032 | val Loss: 1.4235 Acc: 0.5278 | \n","--------------------\n","Epoch 11/50\n","train Loss: 1.0871 Acc: 0.6250 | val Loss: 1.4128 Acc: 0.5183 | \n","--------------------\n","Epoch 12/50\n","train Loss: 1.0521 Acc: 0.6365 | val Loss: 2.0094 Acc: 0.4156 | \n","--------------------\n","Epoch 13/50\n","train Loss: 1.0081 Acc: 0.6530 | val Loss: 1.3171 Acc: 0.5491 | \n","--------------------\n","Epoch 14/50\n","train Loss: 0.9677 Acc: 0.6663 | val Loss: 1.2610 Acc: 0.5749 | \n","--------------------\n","Epoch 15/50\n","train Loss: 0.9417 Acc: 0.6777 | val Loss: 1.1217 Acc: 0.6100 | \n","--------------------\n","Epoch 16/50\n","train Loss: 0.9041 Acc: 0.6868 | val Loss: 1.0628 Acc: 0.6346 | \n","--------------------\n","Epoch 17/50\n","train Loss: 0.8664 Acc: 0.7044 | val Loss: 1.2694 Acc: 0.5665 | \n","--------------------\n","Epoch 18/50\n","train Loss: 0.8449 Acc: 0.7090 | val Loss: 1.0356 Acc: 0.6492 | \n","--------------------\n","Epoch 19/50\n","train Loss: 0.8145 Acc: 0.7214 | val Loss: 1.3582 Acc: 0.5627 | \n","--------------------\n","Epoch 20/50\n","train Loss: 0.7892 Acc: 0.7278 | val Loss: 1.2524 Acc: 0.5780 | \n","--------------------\n","Epoch 21/50\n","train Loss: 0.7643 Acc: 0.7410 | val Loss: 1.0453 Acc: 0.6525 | \n","--------------------\n","Epoch 22/50\n","train Loss: 0.7337 Acc: 0.7498 | val Loss: 1.0374 Acc: 0.6535 | \n","--------------------\n","Epoch 23/50\n","train Loss: 0.7074 Acc: 0.7597 | val Loss: 1.0355 Acc: 0.6620 | \n","--------------------\n","Epoch 24/50\n","train Loss: 0.6838 Acc: 0.7697 | val Loss: 1.1114 Acc: 0.6374 | \n","--------------------\n","Epoch 25/50\n","train Loss: 0.6609 Acc: 0.7786 | val Loss: 1.4445 Acc: 0.5524 | \n","--------------------\n","Epoch 26/50\n","train Loss: 0.6386 Acc: 0.7832 | val Loss: 0.9712 Acc: 0.6723 | \n","--------------------\n","Epoch 27/50\n","train Loss: 0.6226 Acc: 0.7912 | val Loss: 2.6434 Acc: 0.4660 | \n","--------------------\n","Epoch 28/50\n","train Loss: 0.6085 Acc: 0.7910 | val Loss: 1.3766 Acc: 0.5749 | \n","--------------------\n","Epoch 29/50\n","train Loss: 0.5818 Acc: 0.8040 | val Loss: 1.1224 Acc: 0.6480 | \n","--------------------\n","Epoch 30/50\n","train Loss: 0.5581 Acc: 0.8116 | val Loss: 0.9698 Acc: 0.6974 | \n","--------------------\n","Epoch 31/50\n","train Loss: 0.5506 Acc: 0.8112 | val Loss: 1.1012 Acc: 0.6566 | \n","--------------------\n","Epoch 32/50\n","train Loss: 0.5225 Acc: 0.8257 | val Loss: 0.9861 Acc: 0.6855 | \n","--------------------\n","Epoch 33/50\n","train Loss: 0.5089 Acc: 0.8277 | val Loss: 1.2592 Acc: 0.6470 | \n","--------------------\n","Epoch 34/50\n","train Loss: 0.4853 Acc: 0.8388 | val Loss: 1.0126 Acc: 0.6909 | \n","--------------------\n","Epoch 35/50\n","train Loss: 0.4687 Acc: 0.8413 | val Loss: 1.9163 Acc: 0.5617 | \n","--------------------\n","Epoch 36/50\n","train Loss: 0.4651 Acc: 0.8429 | val Loss: 1.2280 Acc: 0.6305 | \n","--------------------\n","Epoch 37/50\n","train Loss: 0.4411 Acc: 0.8561 | val Loss: 1.0096 Acc: 0.6988 | \n","--------------------\n","Epoch 38/50\n","train Loss: 0.4248 Acc: 0.8588 | val Loss: 1.2072 Acc: 0.6480 | \n","--------------------\n","Epoch 39/50\n","train Loss: 0.4071 Acc: 0.8637 | val Loss: 1.1937 Acc: 0.6527 | \n","--------------------\n","Epoch 40/50\n","train Loss: 0.3912 Acc: 0.8691 | val Loss: 1.0906 Acc: 0.6757 | \n","--------------------\n","Epoch 41/50\n","train Loss: 0.3820 Acc: 0.8699 | val Loss: 0.8395 Acc: 0.7347 | \n","--------------------\n","Epoch 42/50\n","train Loss: 0.3586 Acc: 0.8823 | val Loss: 1.1462 Acc: 0.6728 | \n","--------------------\n","Epoch 43/50\n","train Loss: 0.3474 Acc: 0.8836 | val Loss: 1.2592 Acc: 0.6394 | \n","--------------------\n","Epoch 44/50\n","train Loss: 0.3268 Acc: 0.8914 | val Loss: 0.9333 Acc: 0.7316 | \n","--------------------\n","Epoch 45/50\n","train Loss: 0.3225 Acc: 0.8936 | val Loss: 1.3448 Acc: 0.6351 | \n","--------------------\n","Epoch 46/50\n","train Loss: 0.3033 Acc: 0.8991 | val Loss: 0.9804 Acc: 0.7134 | \n","--------------------\n","Epoch 47/50\n","train Loss: 0.2892 Acc: 0.9072 | val Loss: 0.8481 Acc: 0.7483 | \n","--------------------\n","Epoch 48/50\n","train Loss: 0.2771 Acc: 0.9101 | val Loss: 1.6245 Acc: 0.5985 | \n","--------------------\n","Epoch 49/50\n","train Loss: 0.2610 Acc: 0.9162 | val Loss: 1.0492 Acc: 0.7060 | \n","--------------------\n","Epoch 50/50\n","train Loss: 0.2506 Acc: 0.9183 | val Loss: 0.8818 Acc: 0.7409 | \n","```"],"metadata":{"id":"XIV3-9hfWHl5"}},{"cell_type":"code","source":["# pretrained_model=models.resnet18(pretrained=False)\n","# pretrained_model.fc = nn.Linear(512, 10)\n","# # optimizer = optim.Adam(pretrained_model.parameters(), lr=0.001)\n","# optimizer = optim.SGD(pretrained_model.parameters(), lr=0.001, momentum=0.9)\n","# criterion = nn.CrossEntropyLoss().to(device)\n","# # print(\"train_index : {}, val_index : {}\".format(len(train_index), len(val_index)))\n","\n","\n","pt_path = '/content/drive/MyDrive/DL_study_179/weight/week2/3_49_model.pt'\n","loaded_model = torch.load(pt_path)\n","\n","loaded_model.to(device)"],"metadata":{"id":"Pr-vVAoZIIYb","executionInfo":{"status":"ok","timestamp":1656782546884,"user_tz":-540,"elapsed":252,"user":{"displayName":"HS","userId":"14086807755961934596"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f51178df-8e33-44d3-cf5e-a015e549cbe9"},"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"H7J-knsW1j40","executionInfo":{"status":"ok","timestamp":1656782547919,"user_tz":-540,"elapsed":2,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["all_preds = torch.Tensor([]).to(device)\n","all_labels = torch.Tensor([]).to(device)\n","for images, labels in testloader:\n","    \n","    images, labels = images.to(device), labels.to(device)\n","    preds=loaded_model(images).argmax(dim=1).to(device)\n","    all_preds = torch.cat((all_preds, preds), dim=0)\n","    all_labels = torch.cat((all_labels, labels), dim=0)"],"metadata":{"id":"Sg-yoXBy6szg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchmetrics import ConfusionMatrix\n","all_preds = all_preds.clone().detach().type(torch.IntTensor).to(device)\n","all_labels = all_labels.clone().detach().type(torch.IntTensor).to(device)"],"metadata":{"id":"Mqr0ELN2_Jrh","executionInfo":{"status":"ok","timestamp":1656782564172,"user_tz":-540,"elapsed":13,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["confmat = ConfusionMatrix(num_classes=10).to(device)\n","confusion_matrix = confmat(all_preds, all_labels).cpu()"],"metadata":{"id":"tIXikVNDVhp7","executionInfo":{"status":"ok","timestamp":1656782564172,"user_tz":-540,"elapsed":11,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["confusion_matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baAYg9SOUsr4","executionInfo":{"status":"ok","timestamp":1656782564173,"user_tz":-540,"elapsed":11,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"3ac8a642-d1f0-49bd-a49c-c41922e23db2"},"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 34,   0,   0,   0,   0,   1,   0, 387,   1,   0],\n","        [ 22,   2,   0,   0,   0,   7,   0, 301,   2,   0],\n","        [ 32,   0,   1,   0,   0,  14,   0, 573,   0,   0],\n","        [ 21,   0,   0,   0,   0,   2,   0, 351,   0,   0],\n","        [124,   7,   0,   1,   0,  23,   0, 817,   1,   0],\n","        [  8,   0,   0,   0,   0,   2,   0, 280,   0,   0],\n","        [ 27,   0,   0,   0,   0,   5,   0, 491,   2,   0],\n","        [ 14,   0,   1,   0,   0,   2,   0, 347,   0,   0],\n","        [179,   6,   2,   0,   0,  30,   0, 740,   8,   0],\n","        [ 42,   0,   0,   0,   0,  10,   0, 321,   0,   0]])"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["```\n","tensor([[350,   1,   0,   1,   0,   0,   0,   0,   6,   0],\n","        [  0, 265,   1,   2,   7,   2,   0,   2,   1,   0],\n","        [  2,   2, 501,   0,   3,   0,   0,   0,   6,   0],\n","        [  0,   2,   1, 283,   3,   1,   2,  11,   0,   0],\n","        [  3,   7,   4,   7, 730,   4,   6,   5,   0,   5],\n","        [  1,   1,   0,   3,   0, 234,   1,   2,   0,   0],\n","        [  0,   1,   1,   9,   1,   3, 376,   3,   0,   0],\n","        [  0,   0,   0,  12,   2,   3,   1, 267,   2,   0],\n","        [  9,   0,   0,   0,   1,   0,   0,   0, 742,   1],\n","        [  0,   3,   3,   0,   3,   0,   0,   1,   4, 272]])\n","```"],"metadata":{"id":"Q6_ytWefUk_s"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"Vz5PGjVSHwW6"}},{"cell_type":"code","source":["from torchmetrics import F1Score\n","f1 = F1Score(num_classes=10).to(device)\n","f1_score = f1(all_preds, all_labels).cpu()"],"metadata":{"id":"Z9mxXn7iVeF-","executionInfo":{"status":"ok","timestamp":1656780992842,"user_tz":-540,"elapsed":268,"user":{"displayName":"HS","userId":"14086807755961934596"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["f1_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QAnebqDWdM5","executionInfo":{"status":"ok","timestamp":1656780993115,"user_tz":-540,"elapsed":1,"user":{"displayName":"HS","userId":"14086807755961934596"}},"outputId":"680b0b23-9057-49b6-cf51-890fb2f4563f"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.1133)"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["```\n","tensor(0.9599)\n","```"],"metadata":{"id":"OQ_Yp0iKWe_o"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"DL_study_179_week2-1.ipynb","provenance":[],"mount_file_id":"1fXeuOzTvkl3aULdfzxbThpHO0y9R4KIN","authorship_tag":"ABX9TyM8+dh7tNWL6OxfzPTHfnru"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}